{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68c60dd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "382dd0c4",
   "metadata": {},
   "source": [
    "# Morlet Time Frequency Analysis - Visualizations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1547adac",
   "metadata": {},
   "source": [
    "### Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b34f775b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.ticker import ScalarFormatter\n",
    "import seaborn as sns\n",
    "\n",
    "import math\n",
    "import scipy\n",
    "from scipy import stats\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb55a650",
   "metadata": {},
   "source": [
    "### Define dictionaries, subject, & conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "548d4a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to main folder\n",
    "%cd ~/\n",
    "%pwd\n",
    "\n",
    "# path to data files\n",
    "data_path = \"/Volumes/Elements/data_mne/\"\n",
    "\n",
    "# subject \n",
    "subj = ['Bou_Ni'] \n",
    "sub_idx = 0 # subject number\n",
    "\n",
    "# list of conditions\n",
    "condition_list = ['produce_music', 'perceive_music_produced', 'produce_speech', 'perceive_speech_produced']\n",
    "contrasts = [[\"produce_music\", \"perceive_music_produced\"], [\"produce_speech\", \"perceive_speech_produced\"]]\n",
    "contrast_names = [\"Music Production and Music Perception\", \"Speech Production and Speech Perception\"]\n",
    "\n",
    "condition_list_control = ['perceive_music_new', 'perceive_music_newrepetition', 'perceive_speech_new', 'perceive_speech_newrepetition']\n",
    "contrasts_control = [[\"perceive_music_new\", \"perceive_music_newrepetition\"], [\"perceive_speech_new\", \"perceive_speech_newrepetition\"]]\n",
    "contrast_names_control = [\"Music Perception Control and Music Perception Control Repetition\", \"Speech Perception Control and Speech Perception Control Repetition\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb5c7575",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary path \n",
    "dictionary_path = data_path + subj[sub_idx] + \"/dictionary/TFA\"\n",
    "\n",
    "# plot path \n",
    "plot_path = data_path + subj[sub_idx]  + \"/plots/Power-Frequency-Plots/\"\n",
    "\n",
    "# freesurfer path \n",
    "fs_path = data_path + subj[sub_idx]  + '/freesurfer/Bou_Ni/elec_recon/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bb4061",
   "metadata": {},
   "source": [
    "### Load epoch data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2258eb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load epochs\n",
    "epochs = {}\n",
    "\n",
    "for condition in condition_list:\n",
    "    preprocessed_path = data_path + subj[sub_idx] + \"/preprocessed/\" + condition + \"/\"\n",
    "    print(preprocessed_path)\n",
    "\n",
    "    for files in os.listdir(preprocessed_path):\n",
    "        #filename = day + \"_bipolar_epochs_preprocessed.fif\"\n",
    "        filename = \"day1_bipolar_epochs_preprocessed.fif\"\n",
    "\n",
    "        if filename in files:\n",
    "            path = preprocessed_path + files + '/'\n",
    "            epochs[condition] = mne.read_epochs(path)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "838b4d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel names\n",
    "picks = epochs[\"produce_music\"].ch_names\n",
    "\n",
    "# parameters\n",
    "tmin = 0 \n",
    "tmax = 300 #2.999\n",
    "fmin = 1\n",
    "fmax = 180\n",
    "frequencies = np.logspace(np.log10(fmin), np.log10(fmax), num = 50, base = 10)  # log10 freq scale "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6a49668",
   "metadata": {},
   "source": [
    "### Retrieve TFA results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day = 'both'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morlet_results = {}\n",
    "morlet_results_day1 = {}\n",
    "morlet_results_day2 = {}\n",
    "\n",
    "for condition in condition_list:\n",
    "    morlet_results[condition] = {}\n",
    "    morlet_results_day1[condition] = {}\n",
    "    morlet_results_day2[condition] = {}\n",
    "      \n",
    "    concatenated_results = {}\n",
    "\n",
    "    file_path_day1 = f\"{dictionary_path}/{condition}_day1_morlet_results.pickle\"\n",
    "    with open(file_path_day1, 'rb') as f:\n",
    "        day1 = pickle.load(f)\n",
    "\n",
    "    file_path_day2 = f\"{dictionary_path}/{condition}_day2_morlet_results.pickle\"\n",
    "    with open(file_path_day2, 'rb') as f:\n",
    "        day2 = pickle.load(f)\n",
    "\n",
    "    morlet_results[condition] = np.concatenate((day1, day2))\n",
    "    morlet_results_day1[condition] = day1\n",
    "    morlet_results_day2[condition] = day2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "morlet_results_control = {}\n",
    "\n",
    "for condition in condition_list_control:\n",
    "    morlet_results_control[condition] = {}\n",
    "        \n",
    "    file_path_control = f\"{dictionary_path}/{condition}_day1_morlet_results.pickle\"\n",
    "    with open(file_path_control, 'rb') as f:\n",
    "        control = pickle.load(f)\n",
    "\n",
    "    morlet_results_control[condition] = control"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "853ba9a1",
   "metadata": {},
   "source": [
    "# Compare conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44c5a9b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "freq_band_index = [[0,13], [13,20], [20,24], [24,33], [33,42], [42,50]]\n",
    "band_names = [\"Delta\", \"Theta\", \"Alpha\", \"Beta\", \"Low Gamma\", \"High Gamma\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Self Produced Speech and Music: Production - Perception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4b0629c",
   "metadata": {},
   "outputs": [],
   "source": [
    "contrasts = [[\"produce_music\", \"perceive_music_produced\"], [\"produce_speech\", \"perceive_speech_produced\"]]\n",
    "channel_index = 42\n",
    "exponent = 1\n",
    "\n",
    "for n, contrast in enumerate(contrasts): \n",
    "\n",
    "    if \"music\" in contrast[0]: \n",
    "        color_prod = 'purple'\n",
    "        color_perc = 'plum'\n",
    "    elif \"speech\" in contrast[0]: \n",
    "        color_prod = '#008000'\n",
    "        color_perc = '#90EE90'\n",
    "\n",
    "    # Calculate mean across epochs\n",
    "    data_produced = np.mean(morlet_results[contrast[0]][:, channel_index, :], axis=0) \n",
    "    data_new = np.mean(morlet_results[contrast[1]][:, channel_index, :], axis=0)\n",
    "\n",
    "    # Calculate standard error of the mean (SEM)\n",
    "    sem_produced = np.std(morlet_results[contrast[0]][:, channel_index, :], axis=0)  / np.sqrt(morlet_results[contrast[0]].shape[0])\n",
    "    sem_new = np.std(morlet_results[contrast[1]][:, channel_index, :], axis=0) / np.sqrt(morlet_results[contrast[1]].shape[0])\n",
    "\n",
    "    # Mitigate the 1/f effect by multiplying power values by frequency vector\n",
    "    data_produced *= frequencies ** exponent\n",
    "    data_new *= frequencies ** exponent\n",
    "    sem_produced *= frequencies ** exponent\n",
    "    sem_new *= frequencies ** exponent\n",
    "\n",
    "    # Plot the Power Spectrum Density with SEM\n",
    "    fig, ax = plt.subplots(figsize=(12, 3), ncols=1)\n",
    "\n",
    "    # Plot the mean power with SEM shading for production\n",
    "    ax.plot(np.arange(len(frequencies)), data_produced, color=color_prod, label='Production', linewidth=2)\n",
    "    ax.fill_between(np.arange(len(frequencies)), data_produced - sem_produced, data_produced + sem_produced, color=color_prod, alpha=0.3)\n",
    "\n",
    "    # Plot the mean power with SEM shading for perception\n",
    "    ax.plot(np.arange(len(frequencies)), data_new, color=color_perc, label='Perception', linewidth=2)\n",
    "    ax.fill_between(np.arange(len(frequencies)), data_new - sem_new, data_new + sem_new, color=color_perc, alpha=0.3)\n",
    "\n",
    "    ax.set_ylabel('Power', fontsize=16)\n",
    "    ax.legend(fontsize=12, loc='upper right')\n",
    "\n",
    "    ax.set_xticks(np.arange(len(frequencies)))\n",
    "    ax.set_xticklabels(np.around(frequencies, 1), rotation=90, size=12)\n",
    "    ax.set_xlim(-0.5, len(frequencies) - 0.5)\n",
    "\n",
    "    # Adding vertical lines to separate frequency bands\n",
    "    for band_index in [[0, 13], [13, 20], [20, 24], [24, 33], [33, 42]]:\n",
    "        ax.axvline(band_index[1] - 0.5, color=\"black\", lw=1)\n",
    "\n",
    "    # Adding a secondary x-axis for frequency bands\n",
    "    ax2 = ax.twiny()  \n",
    "    ax2.set_xlim(ax.get_xlim()) \n",
    "    band_midpoints = [(index[0] + index[1]) / 2 for index in freq_band_index]\n",
    "    ax2.set_xticks(band_midpoints)  \n",
    "    ax2.set_xticklabels(band_names, rotation=0, ha='center', fontsize=12)  \n",
    "    ax2.tick_params(axis='x', pad=10)  \n",
    "    fig.subplots_adjust(bottom=0.2, top=0.85)\n",
    "\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "244ca93a",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "\n",
    "for n, contrast in enumerate(contrasts): \n",
    "    data_produced = morlet_results[contrast[0]][:,channel_index,:]\n",
    "    data_new = morlet_results[contrast[1]][:,channel_index,:]\n",
    "    \n",
    "    ratio = np.mean(((data_produced - data_new ) / data_new * 100), axis=0)\n",
    "\n",
    "    t, p = stats.ttest_rel(data_produced, data_new)\n",
    "    p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)\n",
    "    t[p_corrected > 0.05] = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8), ncols=1)\n",
    "\n",
    "    im1 = ax.imshow(t, aspect='auto', origin='lower', vmin=-10, vmax=10, interpolation='none',  cmap='seismic')\n",
    "    #im1 = ax.imshow(ratio, aspect='auto', origin='lower', interpolation='none', vmax=80, vmin=-80, cmap=\"seismic\")\n",
    "   \n",
    "    ax.set_xlabel('Frequencies', size=16)\n",
    "    ax.set_ylabel('Channels', size=16)\n",
    "    ax.set_yticks(np.arange(t.shape[0]))\n",
    "    ax.set_yticklabels(picks_H, size=12)\n",
    "    ax.set_xticks(np.arange(len(frequencies)))\n",
    "    ax.set_xticklabels((np.around(frequencies,1)), rotation=90, size=12)\n",
    "    ax.axhline(7.5, color=\"black\", lw=3)\n",
    "    for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "        ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1.5)\n",
    "    for band_index in [[0,13], [13,20], [20,24], [24,33], [33,42]]:\n",
    "        ax.axvline(band_index[1] - 0.5, color=\"black\", lw=1)\n",
    "\n",
    "    ax2 = ax.twiny()  \n",
    "    ax2.set_xlim(ax.get_xlim()) \n",
    "    band_midpoints = [(index[0] + index[1]) / 2 for index in freq_band_index]\n",
    "    ax2.set_xticks(band_midpoints)  \n",
    "    ax2.set_xticklabels(band_names, rotation=0, ha='center', size=12)  \n",
    "    ax2.tick_params(axis='x', pad=10)  \n",
    "    fig.subplots_adjust(bottom=0.2, top=0.85)\n",
    "\n",
    "    ax3 = ax.twinx()  \n",
    "    ax3.set_ylim(ax.get_ylim()) \n",
    "    channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "    ax3.set_yticks(channel_midpoints)  \n",
    "    ax3.set_yticklabels(brain_label, size=12, ha='left')  \n",
    "\n",
    "    colorbar = fig.colorbar(im1, ax=ax, fraction=0.05, pad=0.17)\n",
    "    colorbar.set_label('t-statistics', size=14) \n",
    "\n",
    "    contrast_name = contrast[0] + \"-\" + contrast[1]\n",
    "    #plt.savefig(plot_path + f\"TFA_H-channels_t-statistics_{contrast_name}_power-frequency-plot.jpg\", bbox_inches='tight')\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "\n",
    "for i, morlet_results in enumerate([morlet_results_day1, morlet_results_day2]):\n",
    "    for n, contrast in enumerate(contrasts): \n",
    "        data_produced = morlet_results[contrast[0]][:,channel_index,:]\n",
    "        data_new = morlet_results[contrast[1]][:,channel_index,:]\n",
    "        \n",
    "        t, p = stats.ttest_rel(data_produced, data_new)\n",
    "        p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)\n",
    "        t[p_corrected > 0.05] = 0\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(12, 8), ncols=1)\n",
    "\n",
    "        im1 = ax.imshow(t, aspect='auto', origin='lower', vmin=-10, vmax=10, interpolation='none',  cmap='seismic')\n",
    "    \n",
    "        ax.set_xlabel('Frequencies', size=16)\n",
    "        ax.set_ylabel('Channels', size=16)\n",
    "        ax.set_yticks(np.arange(t.shape[0]))\n",
    "        ax.set_yticklabels(picks_H, size=12)\n",
    "        ax.set_xticks(np.arange(len(frequencies)))\n",
    "        ax.set_xticklabels((np.around(frequencies,1)), rotation=90, size=12)\n",
    "        ax.axhline(7.5, color=\"black\", lw=3)\n",
    "        for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "            ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1.5)\n",
    "        for band_index in [[0,13], [13,20], [20,24], [24,33], [33,42]]:\n",
    "            ax.axvline(band_index[1] - 0.5, color=\"black\", lw=1)\n",
    "\n",
    "        ax2 = ax.twiny()  \n",
    "        ax2.set_xlim(ax.get_xlim()) \n",
    "        band_midpoints = [(index[0] + index[1]) / 2 for index in freq_band_index]\n",
    "        ax2.set_xticks(band_midpoints)  \n",
    "        ax2.set_xticklabels(band_names, rotation=0, ha='center', size=12)  \n",
    "        ax2.tick_params(axis='x', pad=10)  \n",
    "        fig.subplots_adjust(bottom=0.2, top=0.85)\n",
    "\n",
    "        ax3 = ax.twinx()  \n",
    "        ax3.set_ylim(ax.get_ylim()) \n",
    "        channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "        ax3.set_yticks(channel_midpoints)  \n",
    "        ax3.set_yticklabels(brain_label, size=12, ha='left')  \n",
    "\n",
    "        colorbar = fig.colorbar(im1, ax=ax, fraction=0.05, pad=0.17)\n",
    "        colorbar.set_label('t-statistics', size=14) \n",
    "\n",
    "        contrast_name = contrast[0] + \"-\" + contrast[1]\n",
    "        #plt.savefig(plot_path + f\"TFA_H-channels_t-statistics_{contrast_name}_{day}_power-frequency-plot.jpg\", bbox_inches='tight')\n",
    "        plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c96ded36",
   "metadata": {},
   "source": [
    "### Linear mixed effect models\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b9793c4",
   "metadata": {},
   "source": [
    "#### Model for music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "799b3e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "frequencies = np.logspace(np.log10(fmin), np.log10(fmax), num = 50, base = 10)  \n",
    "epochs=np.r_[0:100]\n",
    "data = []\n",
    "for day, morlet_results in zip(['Day1', 'Day2'], [morlet_results_day1, morlet_results_day2]):\n",
    "    for condition in ['produce_music', 'perceive_music_produced']:\n",
    "        for pick, channel_idx in zip(picks_H, channel_index):\n",
    "            for freq_idx, freq in enumerate(frequencies):\n",
    "                for epoch_idx in epochs:\n",
    "                    result = morlet_results[condition][epoch_idx, channel_idx, freq_idx]\n",
    "                    data.append({\n",
    "                        'Subject': 'BouNi', \n",
    "                        'Condition': condition, \n",
    "                        'Day': day, \n",
    "                        'Channel': pick, \n",
    "                        'Frequency': freq, \n",
    "                        'Epoch': epoch_idx, \n",
    "                        'Score': result\n",
    "                    })\n",
    "\n",
    "data_music = pd.DataFrame(data)\n",
    "\n",
    "data_music['Condition'] = pd.Categorical(data_music['Condition'], \n",
    "                                          categories=['produce_music', 'perceive_music_produced'],\n",
    "                                          ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fcb6d72",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Score ~ C(Condition)\", data_music, groups=data_music[\"Subject\"])\n",
    "result = model.fit()\n",
    "print(\"music\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edf29dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print the coefficients with higher precision\n",
    "print(\"Model Coefficients (unrounded):\")\n",
    "params = result.params\n",
    "for param in params.index:\n",
    "    print(f\"{param}: {params[param]:.3e}\")\n",
    "\n",
    "# Extract and print the standard errors\n",
    "print(\"\\nStandard Errors (unrounded):\")\n",
    "bse = result.bse\n",
    "for param in bse.index:\n",
    "    print(f\"{param}: {bse[param]:.3e}\")\n",
    "\n",
    "# Extract and print p-values\n",
    "print(\"\\nP-values (unrounded):\")\n",
    "pvalues = result.pvalues\n",
    "for param in pvalues.index:\n",
    "    print(f\"{param}: {pvalues[param]:.3e}\")\n",
    "\n",
    "# Extract and print confidence intervals\n",
    "print(\"\\nConfidence Intervals (unrounded):\")\n",
    "conf_int = result.conf_int()\n",
    "for param in conf_int.index:\n",
    "    print(f\"{param}: [{conf_int.loc[param][0]:.3e}, {conf_int.loc[param][1]:.3e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "069773ae",
   "metadata": {},
   "source": [
    "#### Model for speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66aeb32c",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "frequencies = np.logspace(np.log10(fmin), np.log10(fmax), num = 50, base = 10)  \n",
    "epochs=np.r_[0:100]\n",
    "data = []\n",
    "for day, morlet_results in zip(['Day1', 'Day2'], [morlet_results_day1, morlet_results_day2]):\n",
    "    for condition in ['produce_speech', 'perceive_speech_produced']:\n",
    "        for pick, channel_idx in zip(picks_H, channel_index):\n",
    "            for freq_idx, freq in enumerate(frequencies):\n",
    "                for epoch_idx in epochs:\n",
    "                    result = morlet_results[condition][epoch_idx, channel_idx, freq_idx]\n",
    "                    data.append({\n",
    "                        'Subject': 'BouNi', \n",
    "                        'Condition': condition, \n",
    "                        'Day': day, \n",
    "                        'Channel': pick, \n",
    "                        'Frequency': freq, \n",
    "                        'Epoch': epoch_idx, \n",
    "                        'Score': result\n",
    "                    })\n",
    "\n",
    "data_speech = pd.DataFrame(data)\n",
    "\n",
    "data_speech['Condition'] = pd.Categorical(data_speech['Condition'], \n",
    "                                          categories=['produce_speech', 'perceive_speech_produced'],\n",
    "                                          ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79797e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Score ~ C(Condition)\", data_speech, groups=data_speech[\"Subject\"])\n",
    "result = model.fit()\n",
    "print(\"speech\")\n",
    "print(result.summary().as_text())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2a1bb8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print the coefficients with higher precision\n",
    "print(\"Model Coefficients (unrounded):\")\n",
    "params = result.params\n",
    "for param in params.index:\n",
    "    print(f\"{param}: {params[param]:.3e}\")\n",
    "\n",
    "# Extract and print the standard errors\n",
    "print(\"\\nStandard Errors (unrounded):\")\n",
    "bse = result.bse\n",
    "for param in bse.index:\n",
    "    print(f\"{param}: {bse[param]:.3e}\")\n",
    "\n",
    "# Extract and print p-values\n",
    "print(\"\\nP-values (unrounded):\")\n",
    "pvalues = result.pvalues\n",
    "for param in pvalues.index:\n",
    "    print(f\"{param}: {pvalues[param]:.3e}\")\n",
    "\n",
    "# Extract and print confidence intervals\n",
    "print(\"\\nConfidence Intervals (unrounded):\")\n",
    "conf_int = result.conf_int()\n",
    "for param in conf_int.index:\n",
    "    print(f\"{param}: [{conf_int.loc[param][0]:.3e}, {conf_int.loc[param][1]:.3e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Speech and Music Repetition: First Hearing - Second Hearing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e47ce70",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "\n",
    "for n, contrast in enumerate(contrasts_control): \n",
    "    data_firsthearing = morlet_results_control[contrast[0]][:,channel_index,:]\n",
    "    data_secondhearing = morlet_results_control[contrast[1]][:,channel_index,:]\n",
    "    \n",
    "    ratio = np.mean(((data_firsthearing - data_secondhearing ) / data_secondhearing * 100), axis=0)\n",
    "\n",
    "    t, p = stats.ttest_rel(data_firsthearing, data_secondhearing)\n",
    "    p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)\n",
    "    t[p_corrected > 0.05] = 0\n",
    "    \n",
    "    fig, ax = plt.subplots(figsize=(12, 8), ncols=1)\n",
    "\n",
    "    im1 = ax.imshow(t, aspect='auto', origin='lower', vmin=-10, vmax=10, interpolation='none',  cmap='seismic')\n",
    "    ax.set_xlabel('Frequencies', size=16)\n",
    "    ax.set_ylabel('Channels', size=16)\n",
    "    ax.set_yticks(np.arange(t.shape[0]))\n",
    "    ax.set_yticklabels(picks_H, size=12)\n",
    "    ax.set_xticks(np.arange(len(frequencies)))\n",
    "    ax.set_xticklabels((np.around(frequencies,1)), rotation=90, size=12)\n",
    "    ax.axhline(7.5, color=\"black\", lw=3)\n",
    "    for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "        ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1.5)\n",
    "    for band_index in [[0,13], [13,20], [20,24], [24,33], [33,42]]:\n",
    "        ax.axvline(band_index[1] - 0.5, color=\"black\", lw=1)\n",
    "\n",
    "    ax2 = ax.twiny()  \n",
    "    ax2.set_xlim(ax.get_xlim()) \n",
    "    band_midpoints = [(index[0] + index[1]) / 2 for index in freq_band_index]\n",
    "    ax2.set_xticks(band_midpoints)  \n",
    "    ax2.set_xticklabels(band_names, rotation=0, ha='center', size=12)  \n",
    "    ax2.tick_params(axis='x', pad=10)  \n",
    "    fig.subplots_adjust(bottom=0.2, top=0.85)\n",
    "\n",
    "    ax3 = ax.twinx()  \n",
    "    ax3.set_ylim(ax.get_ylim()) \n",
    "    channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "    ax3.set_yticks(channel_midpoints)  \n",
    "    ax3.set_yticklabels(brain_label, size=12, ha='left')  \n",
    "\n",
    "    colorbar = fig.colorbar(im1, ax=ax, fraction=0.05, pad=0.17)\n",
    "    colorbar.set_label('t-statistics', size=14) \n",
    "\n",
    "    contrast_name = contrast[0] + \"-\" + contrast[1]\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5140d8b",
   "metadata": {},
   "source": [
    "### Linear mixed effect models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7924937",
   "metadata": {},
   "source": [
    "#### Model for music "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8aa50d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "frequencies = np.logspace(np.log10(fmin), np.log10(fmax), num=50, base=10)\n",
    "epochs = np.r_[0:100]\n",
    "\n",
    "data = []\n",
    "\n",
    "for condition in ['perceive_music_new', 'perceive_music_newrepetition']:\n",
    "    for pick, channel_idx in zip(picks_H, channel_index):\n",
    "        for freq_idx, freq in enumerate(frequencies):\n",
    "            for epoch_idx in epochs:\n",
    "                result = morlet_results_control[condition][epoch_idx, channel_idx, freq_idx]\n",
    "                data.append({\n",
    "                    'Subject': 'BouNi', \n",
    "                    'Condition': condition, \n",
    "                    'Channel': pick, \n",
    "                    'Frequency': freq, \n",
    "                    'Epoch': epoch_idx, \n",
    "                    'Score': result\n",
    "                })\n",
    "\n",
    "data_music = pd.DataFrame(data)\n",
    "\n",
    "data_music['Condition'] = pd.Categorical(data_music['Condition'], \n",
    "                                          categories=['perceive_music_new', 'perceive_music_newrepetition'],\n",
    "                                          ordered=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3297e8da",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Score ~ Condition \", data_music, groups=data_music[\"Subject\"])\n",
    "result = model.fit()\n",
    "print(\"speech\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a093316",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print the coefficients with higher precision\n",
    "print(\"Model Coefficients (unrounded):\")\n",
    "params = result.params\n",
    "for param in params.index:\n",
    "    print(f\"{param}: {params[param]:.3e}\")\n",
    "\n",
    "# Extract and print the standard errors\n",
    "print(\"\\nStandard Errors (unrounded):\")\n",
    "bse = result.bse\n",
    "for param in bse.index:\n",
    "    print(f\"{param}: {bse[param]:.3e}\")\n",
    "\n",
    "# Extract and print p-values\n",
    "print(\"\\nP-values (unrounded):\")\n",
    "pvalues = result.pvalues\n",
    "for param in pvalues.index:\n",
    "    print(f\"{param}: {pvalues[param]:.3e}\")\n",
    "\n",
    "# Extract and print confidence intervals\n",
    "print(\"\\nConfidence Intervals (unrounded):\")\n",
    "conf_int = result.conf_int()\n",
    "for param in conf_int.index:\n",
    "    print(f\"{param}: [{conf_int.loc[param][0]:.3e}, {conf_int.loc[param][1]:.3e}]\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1947aa83",
   "metadata": {},
   "source": [
    "#### Model for speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5853914",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "frequencies = np.logspace(np.log10(fmin), np.log10(fmax), num=50, base=10)\n",
    "epochs = np.r_[0:100]\n",
    "\n",
    "data = []\n",
    "\n",
    "for condition in ['perceive_speech_new', 'perceive_speech_newrepetition']:\n",
    "    print(condition)\n",
    "    for pick, channel_idx in zip(picks_H, channel_index):\n",
    "        for freq_idx, freq in enumerate(frequencies):\n",
    "            for epoch_idx in epochs:\n",
    "                result = morlet_results_control[condition][epoch_idx, channel_idx, freq_idx]\n",
    "                data.append({\n",
    "                    'Subject': 'BouNi', \n",
    "                    'Condition': condition, \n",
    "                    'Channel': pick, \n",
    "                    'Frequency': freq, \n",
    "                    'Epoch': epoch_idx, \n",
    "                    'Score': result\n",
    "                })\n",
    "\n",
    "data_speech = pd.DataFrame(data)\n",
    "\n",
    "data_speech['Condition'] = pd.Categorical(data_speech['Condition'], \n",
    "                                          categories=['perceive_speech_new', 'perceive_speech_newrepetition'],\n",
    "                                          ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd7a11fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Score ~ Condition\", data_speech, groups=data_speech[\"Subject\"])\n",
    "result = model.fit()\n",
    "print(\"speech\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f6a949",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract and print the coefficients with higher precision\n",
    "print(\"Model Coefficients (unrounded):\")\n",
    "params = result.params\n",
    "for param in params.index:\n",
    "    print(f\"{param}: {params[param]:.3e}\")\n",
    "\n",
    "# Extract and print the standard errors\n",
    "print(\"\\nStandard Errors (unrounded):\")\n",
    "bse = result.bse\n",
    "for param in bse.index:\n",
    "    print(f\"{param}: {bse[param]:.3e}\")\n",
    "\n",
    "# Extract and print p-values\n",
    "print(\"\\nP-values (unrounded):\")\n",
    "pvalues = result.pvalues\n",
    "for param in pvalues.index:\n",
    "    print(f\"{param}: {pvalues[param]:.3e}\")\n",
    "\n",
    "# Extract and print confidence intervals\n",
    "print(\"\\nConfidence Intervals (unrounded):\")\n",
    "conf_int = result.conf_int()\n",
    "for param in conf_int.index:\n",
    "    print(f\"{param}: [{conf_int.loc[param][0]:.3e}, {conf_int.loc[param][1]:.3e}]\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
