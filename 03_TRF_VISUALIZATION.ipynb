{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf62157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b5b33",
   "metadata": {},
   "source": [
    "# Temporal Response Function (TRF) - Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f993e9",
   "metadata": {},
   "source": [
    "### Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79bede75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne \n",
    "import pickle\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113a134",
   "metadata": {},
   "source": [
    "### Define dictionaries, subject, & conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to main folder\n",
    "%cd ~/\n",
    "%pwd\n",
    "\n",
    "# path to data files\n",
    "data_path = \"/../data/\"\n",
    "\n",
    "# subject \n",
    "subj = ['Bou_Ni'] \n",
    "sub_idx = 0 # subject number\n",
    "\n",
    "# frequency band \n",
    "band_name = \"Low Frequencies\"\n",
    "band = \"deltatheta\" \n",
    "\n",
    "# list of conditions\n",
    "condition_list = ['produce_music', 'perceive_music_produced', 'produce_speech', 'perceive_speech_produced']\n",
    "contrasts = [[\"produce_music\", \"perceive_music_produced\"], [\"produce_speech\", \"perceive_speech_produced\"]]\n",
    "pairs = [[\"music\",\"produce_music\"], [\"music\", \"perceive_music_produced\"], [\"speech\", \"produce_speech\"], [\"speech\", \"perceive_speech_produced\"]]\n",
    "contrasts = [[\"produce_music\", \"perceive_music_produced\"], [\"produce_speech\", \"perceive_speech_produced\"]]\n",
    "condition_names = [\"Music \\n Production\", \"Music \\n Perception\", \"Speech \\n Production\", \"Speech \\n Perception\"]\n",
    "contrast_names = [\"Music Production And Music Perception\", \"Speech Production and Speech Perception\"]\n",
    "\n",
    "condition_list_control = ['perceive_music_new', 'perceive_music_newrepetition', 'perceive_speech_new', 'perceive_speech_newrepetition']\n",
    "contrasts_control = [[\"perceive_music_new\", \"perceive_music_newrepetition\"], [\"perceive_speech_new\", \"perceive_speech_newrepetition\"]]\n",
    "pairs_control = [[\"perceive_music_new\", \"perceive_music_newrepetition\"], [\"speech_new\", \"perceive_speech_new\"], [\"speech_new\", \"perceive_speech_newrepetition\"]]\n",
    "condition_names_control = [\"Music \\n Perception \\n Control\", \"Music \\n Perception \\n Control Repetition\", \"Speech \\n Perception \\n Control\", \"Speech \\n Perception \\n Control Repetition\", ]\n",
    "contrast_names_control = [\"Music First Hearing And Music Second Hearing\", \"Speech First Hearing and Speech Second Hearing\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary path \n",
    "dictionary_path = data_path + subj[sub_idx] + \"/dictionary\"\n",
    "\n",
    "# plot path \n",
    "plot_path = data_path + subj[sub_idx] + \"/plots/Temporal-Response-Function-Plots/\"\n",
    "\n",
    "# freesurfer path \n",
    "fs_path = data_path + subj[sub_idx] + '/freesurfer/Bou_Ni/elec_recon/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6aedf",
   "metadata": {},
   "source": [
    "### Load raw data and channel information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51fcc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load in raw \n",
    "raw = {}\n",
    "\n",
    "for condition in condition_list:\n",
    "    preprocessed_path = data_path + subj[sub_idx] + \"/preprocessed/\" + condition + \"/\"\n",
    "    preprocessed_path = \"/.../data/preprocessed/\" + condition + \"/\"\n",
    "\n",
    "    for files in os.listdir(preprocessed_path):\n",
    "        filename = \"day1_bipolar_raw_preprocessed.fif\"\n",
    "        if filename in files:\n",
    "            path = preprocessed_path + files + '/'\n",
    "            raw[condition] =  mne.io.read_raw_fif(path, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbf60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel names (picks)\n",
    "picks = raw['produce_music'].ch_names\n",
    "\n",
    "# define channels in the auditory cortex \n",
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "print('channels in auditory cortex: ', picks_H)\n",
    "\n",
    "# assign channels to LH and RH primary and non-primary auditory cortex \n",
    "picks_primary_RH = ['H5-H6', 'H6-H7', 'H7-H8', 'H8-H9', 'H9-H10', 'H10-H11']\n",
    "picks_primary_LH = [ \"H'5-H'6\", \"H'6-H'7\", \"H'7-H'8\", \"H'8-H'9\"]\n",
    "picks_nonprimary_RH = ['H11-H12', 'H12-H13']\n",
    "picks_nonprimary_LH = [ \"H'9-H'10\", \"H'10-H'11\", \"H'11-H'12\"]\n",
    "\n",
    "picks_subset = [picks_primary_LH, picks_nonprimary_LH, picks_primary_RH, picks_nonprimary_RH,]\n",
    "picks_subset_names = [\"Left Primary Auditory Cortex\", \"Left Associative Auditory Cortex\", \"Right Primary Auditory Cortex\", \"Right Associative Auditory Cortex\"] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50adc62",
   "metadata": {},
   "source": [
    "### Load accoustic regressors and TRF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dce551ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressors  \n",
    "with open(f\"/.../data/dictionary/analysis/TRF_regressors_deltatheta_day1.pickle\", 'rb') as f:\n",
    "        regressors1 = pickle.load(f)\n",
    "\n",
    "with open(f\"/.../data/dictionary/analysis/TRF_regressors_deltatheta_day2.pickle\", 'rb') as f:\n",
    "        regressors2 = pickle.load(f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TRF crossvalidated data for H-channels \n",
    "with open(f\"/.../data/dictionary/analysis/TRF_results_deltatheta_day1_crossvalidate.pickle\", 'rb') as f:\n",
    "        TRF1 = pickle.load(f)\n",
    "\n",
    "with open(f\"/.../data/dictionary/analysis/TRF_results_deltatheta_day2_crossvalidate.pickle\", 'rb') as f:\n",
    "        TRF2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "faa33be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "labels = regressors1['music'][1]\n",
    "fs = 100\n",
    "scoring = 'r2'\n",
    "tw = [-0.2, 0.5]                                           "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf2ef8",
   "metadata": {},
   "source": [
    "# Compare conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31d25a",
   "metadata": {},
   "source": [
    "## Self Produced Speech and Music: Production - Perception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate data from two days\n",
    "TRF = {}\n",
    "for condition in condition_list: \n",
    "        TRF[condition] = {}\n",
    "        for pick in picks_H: \n",
    "                TRF[condition][pick] = {}\n",
    "                TRF[condition][pick]['score'] = np.concatenate((TRF1[condition][pick]['score'], TRF2[condition][pick]['score']), axis=0)\n",
    "                TRF[condition][pick]['coefs'] = np.concatenate((TRF1[condition][pick]['coefs'], TRF2[condition][pick]['coefs']), axis=0)\n",
    "                TRF[condition][pick]['predicted_Y'] = np.concatenate((TRF1[condition][pick]['predicted_Y'], TRF2[condition][pick]['predicted_Y']), axis=0)\n",
    "                TRF[condition][pick]['times'] = TRF1[condition][pick]['times'] # same across two days \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TRF for main analysis for day1\n",
    "TRF_day1 = {}\n",
    "for condition in condition_list: \n",
    "        TRF_day1[condition] = {}\n",
    "        for pick in picks_H: \n",
    "                TRF_day1[condition][pick] = {}\n",
    "                TRF_day1[condition][pick]['score'] = TRF1[condition][pick]['score']\n",
    "                TRF_day1[condition][pick]['coefs'] = TRF1[condition][pick]['coefs']\n",
    "                TRF_day1[condition][pick]['predicted_Y'] = TRF1[condition][pick]['predicted_Y']\n",
    "                TRF_day1[condition][pick]['times'] = TRF1[condition][pick]['times'] \n",
    "\n",
    "# load TRF for main analysis for day1\n",
    "TRF_day2 = {}\n",
    "for condition in condition_list: \n",
    "        TRF_day2[condition] = {}\n",
    "        for pick in picks_H: \n",
    "                TRF_day2[condition][pick] = {}\n",
    "                TRF_day2[condition][pick]['score'] = TRF2[condition][pick]['score']\n",
    "                TRF_day2[condition][pick]['coefs'] = TRF2[condition][pick]['coefs']\n",
    "                TRF_day2[condition][pick]['predicted_Y'] = TRF2[condition][pick]['predicted_Y']\n",
    "                TRF_day2[condition][pick]['times'] = TRF2[condition][pick]['times'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRF shape \n",
    "pick = 'H5-H6'\n",
    "i_reg = 5 # loadness derivative\n",
    "colors = ['purple', 'plum', '#008000', '#90EE90']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "for n, condition in enumerate(condition_list):\n",
    "    times = TRF[condition][pick]['times']\n",
    "\n",
    "    coefs_pick = TRF[condition][pick][\"coefs\"]\n",
    "    coefs_mean = np.mean(coefs_pick[:, i_reg, :], axis=0)\n",
    "    ax.plot(times, coefs_mean, label=condition_names[n], color=colors[n], linewidth=3)\n",
    "\n",
    "\n",
    "ax.hlines(0, times[0], times[1], colors='gray', linestyles='--')\n",
    "\n",
    "ax.legend(loc='upper right', prop={'size': 8})\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "channel_assignment = [0, 6, 8, 12, len(picks_H)]\n",
    "\n",
    "for n, contrast in enumerate(contrasts):\n",
    "    if \"music\" in contrast[0]: \n",
    "        color_prod = 'purple'\n",
    "        color_perc = 'plum'\n",
    "    elif \"speech\" in contrast[0]: \n",
    "        color_prod = '#008000'\n",
    "        color_perc = '#90EE90'\n",
    "\n",
    "        \n",
    "    data_production = np.array([TRF[contrast[0]][pick]['score'] for pick in picks_H])\n",
    "    data_perception = np.array([TRF[contrast[1]][pick]['score'] for pick in picks_H])\n",
    "\n",
    "    mean_production = np.mean(data_production, axis=1)\n",
    "    se_production = np.std(data_production, axis=1, ddof=1) / np.sqrt(len(data_production[0]))\n",
    "\n",
    "    mean_perception = np.mean(data_perception, axis=1)\n",
    "    se_perception = np.std(data_perception, axis=1, ddof=1) / np.sqrt(len(data_perception[0]))\n",
    "\n",
    "    # t-test\n",
    "    t, p = stats.stats.ttest_rel(data_production.T, data_perception.T)\n",
    "    p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)    \n",
    "    significance_threshold = 0.05\n",
    "    significant_channels = np.where(p_corrected < significance_threshold)[0]\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax2 = ax.twinx()  \n",
    "  \n",
    "    ## plot means, se  \n",
    "    for c in range(len(channel_assignment)-1):\n",
    "        ax.errorbar(mean_production[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_production[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_prod, capsize=8)\n",
    "        ax.errorbar(mean_perception[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_perception[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_perc, capsize=8)\n",
    "    \n",
    "    ## plot significant differences\n",
    "    for s in range(len(picks_H)):\n",
    "        if p_corrected[s] < 0.05:\n",
    "            x_pos = - 0.025\n",
    "            y_pos = s - 0.15\n",
    "            ax.text(x_pos, y_pos, \"*\", fontsize=20, color='black', ha='center', va='center', zorder=3)\n",
    "\n",
    "    #ax.set_title(f'r$^2$ Coeffients for {contrast_names[n]} \\n', fontsize=16)\n",
    "    ax.set_xlabel('\\n r$^2$-coefficients', fontsize=16)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.set_ylabel('Channels', fontsize=16)\n",
    "    ax.set_xlim([-0.05, 0.42])\n",
    "    ax.set_yticks(np.arange(len(picks_H)))\n",
    "    ax.set_yticklabels(picks_H, fontsize=14)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "        ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1)\n",
    "    ax2.set_ylim(ax.get_ylim()) \n",
    "    channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "    ax2.set_yticks(channel_midpoints)  \n",
    "    ax2.set_yticklabels(brain_label, size=14, va='center')  \n",
    "\n",
    "    legend_handles = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=color_prod, markersize=15, label='Production'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=color_perc, markersize=15, label='Perception')\n",
    "    ]\n",
    "\n",
    "    ax.legend(handles=legend_handles, fontsize=13) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beba24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot seperatly for the days \n",
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "channel_assignment = [0, 6, 8, 12, len(picks_H)]\n",
    "\n",
    "for day, TRF in zip(['Day1', 'Day2'], [TRF1, TRF2]):\n",
    "    for n, contrast in enumerate(contrasts):\n",
    "        if \"music\" in contrast[0]: \n",
    "            color_prod = 'purple'\n",
    "            color_perc = 'plum'\n",
    "        elif \"speech\" in contrast[0]: \n",
    "            color_prod = '#008000'\n",
    "            color_perc = '#90EE90'\n",
    "\n",
    "        data_production = np.array([TRF[contrast[0]][pick]['score'] for pick in picks_H])\n",
    "        data_perception = np.array([TRF[contrast[1]][pick]['score'] for pick in picks_H])\n",
    "\n",
    "        mean_production = np.mean(data_production, axis=1)\n",
    "        se_production = np.std(data_production, axis=1, ddof=1) / np.sqrt(len(data_production[0]))\n",
    "\n",
    "        mean_perception = np.mean(data_perception, axis=1)\n",
    "        se_perception = np.std(data_perception, axis=1, ddof=1) / np.sqrt(len(data_perception[0]))\n",
    "\n",
    "        # t-test\n",
    "        t, p = stats.stats.ttest_rel(data_production.T, data_perception.T)\n",
    "        p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)    \n",
    "        significance_threshold = 0.05\n",
    "        significant_channels = np.where(p_corrected < significance_threshold)[0]\n",
    "\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax2 = ax.twinx()  \n",
    "    \n",
    "        ## plot means, se  \n",
    "        for c in range(len(channel_assignment)-1):\n",
    "            ax.errorbar(mean_production[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_production[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_prod, capsize=8)\n",
    "            ax.errorbar(mean_perception[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_perception[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_perc, capsize=8)\n",
    "        \n",
    "\n",
    "        ## plot significant differences\n",
    "        for s in range(len(picks_H)):\n",
    "            if p_corrected[s] < 0.05:\n",
    "                x_pos = - 0.025\n",
    "                y_pos = s - 0.15\n",
    "                ax.text(x_pos, y_pos, \"*\", fontsize=20, color='black', ha='center', va='center', zorder=3)\n",
    "\n",
    "        ax.set_xlabel('\\n r$^2$-coefficients', fontsize=16)\n",
    "        ax.tick_params(axis='x', labelsize=16)\n",
    "        ax.set_ylabel('Channels', fontsize=16)\n",
    "        ax.set_xlim([-0.05, 0.42])\n",
    "        ax.set_yticks(np.arange(len(picks_H)))\n",
    "        ax.set_yticklabels(picks_H, fontsize=14)\n",
    "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "            ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1)\n",
    "        ax2.set_ylim(ax.get_ylim()) \n",
    "        channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "        ax2.set_yticks(channel_midpoints)  \n",
    "        ax2.set_yticklabels(brain_label, size=14, va='center')  \n",
    "\n",
    "        legend_handles = [\n",
    "            Line2D([0], [0], marker='o', color='w', markerfacecolor=color_prod, markersize=15, label='Production'),\n",
    "            Line2D([0], [0], marker='o', color='w', markerfacecolor=color_perc, markersize=15, label='Perception')\n",
    "        ]\n",
    "\n",
    "        ax.legend(handles=legend_handles, fontsize=13) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear mixed effects model \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bc427a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def custom_round(val, threshold=1e-5, decimals=3):\n",
    "    if abs(val) < threshold:\n",
    "        return f\"{val:.{decimals}e}\"\n",
    "    else:\n",
    "        return round(val, decimals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "97761284",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define channel groups\n",
    "picks_primary_RH = ['H5-H6', 'H6-H7', 'H7-H8', 'H8-H9', 'H9-H10', 'H10-H11']\n",
    "picks_primary_LH = [\"H'5-H'6\", \"H'6-H'7\", \"H'7-H'8\", \"H'8-H'9\"]\n",
    "picks_nonprimary_RH = ['H11-H12', 'H12-H13']\n",
    "picks_nonprimary_LH = [\"H'9-H'10\", \"H'10-H'11\", \"H'11-H'12\"]\n",
    "\n",
    "# Create a dictionary for mapping channels to regions\n",
    "channel_to_region = {}\n",
    "\n",
    "# Add each channel group to the mapping\n",
    "for ch in picks_primary_RH:\n",
    "    channel_to_region[ch] = 'Primary_RH'\n",
    "for ch in picks_primary_LH:\n",
    "    channel_to_region[ch] = 'Primary_LH'\n",
    "for ch in picks_nonprimary_RH:\n",
    "    channel_to_region[ch] = 'Non_primary_RH'\n",
    "for ch in picks_nonprimary_LH:\n",
    "    channel_to_region[ch] = 'Non_primary_LH'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77adc3b",
   "metadata": {},
   "source": [
    "### Model for music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for day, TRF in zip(['Day1', 'Day2'], [TRF1, TRF2]):\n",
    "    for condition in ['produce_music', 'perceive_music_produced']:\n",
    "        for pick in picks_H:\n",
    "            score = TRF[condition][pick]['score']\n",
    "            for sc in score:  \n",
    "                data.append({'Subject': 'BouNi', 'Condition': condition, 'Day': day, 'Channel': pick, 'Score': sc})\n",
    "\n",
    "\n",
    "data_music = pd.DataFrame(data)\n",
    "\n",
    "data_music['Condition'] = pd.Categorical(data_music['Condition'], \n",
    "                                          categories=['produce_music', 'perceive_music_produced'],\n",
    "                                          ordered=True)\n",
    "data_music['Region'] = data_music['Channel'].map(channel_to_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "model = smf.mixedlm(\"Score ~ C(Condition)\", data_music, groups=data_music[\"Channel\"]).fit(reml=False)\n",
    "#print(model.summary())\n",
    "\n",
    "results_list = []\n",
    "if model:\n",
    "    params = model.params\n",
    "    pvalues = model.pvalues\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    std_errs = model.bse  \n",
    "    tvalues = model.tvalues  \n",
    "    conf_int = model.conf_int()  \n",
    "    \n",
    "    for effect, coefficient in params.items():\n",
    "        t_value = tvalues.get(effect, None)\n",
    "        std_err = std_errs.get(effect, None)\n",
    "        lower_bound, upper_bound = conf_int.loc[effect].values\n",
    "        \n",
    "        results_list.append({\n",
    "            \"effect\": effect,\n",
    "            \"coef\": custom_round(coefficient),  \n",
    "            \"SE\": custom_round(std_err),        \n",
    "            \"p\": custom_round(pvalues.get(effect, None)),  \n",
    "            \"t\": custom_round(t_value),        \n",
    "            \"[0.025\": custom_round(lower_bound),  \n",
    "            \"0.975]\": custom_round(upper_bound), \n",
    "            #\"AIC\": custom_round(aic),           \n",
    "            #\"BIC\": custom_round(bic),          \n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc6cee1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Models \n",
    "model_results = {}\n",
    "results_list = []\n",
    "\n",
    "# Model 1: Fixed effect of Condition \n",
    "model1 = smf.mixedlm(\n",
    "    formula=\"Score ~ C(Condition)\",  \n",
    "    data=data_music,\n",
    "    groups=data_music[\"Channel\"]  \n",
    ").fit(reml=False)\n",
    "model_results[band_name] = {\"Model Condition\": model1}\n",
    "\n",
    "\n",
    "# Model 2: Fixed effects of Condition and Region\n",
    "model2 = smf.mixedlm(\n",
    "    formula=\"Score ~ C(Condition) + C(Region)\",  \n",
    "    data=data_music,\n",
    "    groups=data_music[\"Channel\"]  \n",
    ").fit(reml=False)\n",
    "\n",
    "model_results[band_name][\"Model Condition + Region\"] = model2\n",
    "\n",
    "# Likelihood Ratio Test statistic\n",
    "ll_model_1 = model1.llf  \n",
    "ll_model_2 = model2.llf  \n",
    "num_params_model_1 = len(model1.params)\n",
    "num_params_model_2 = len(model2.params)\n",
    "\n",
    "lr_statistic = 2 * (ll_model_2 - ll_model_1)\n",
    "df_diff = num_params_model_2 - num_params_model_1\n",
    "p_value = 1 - stats.chi2.cdf(lr_statistic, df_diff)\n",
    "\n",
    "print(f\"Likelihood Ratio Test between Model 1 and Model 2: Statistic = {lr_statistic}, p-value = {p_value}\")\n",
    "\n",
    "results_list.append({\n",
    "    \"Stimuli\": \"music\", \n",
    "    \"Model1\": \"Condition\",\n",
    "    \"Model2\": \"Condition + Region\",\n",
    "    \"AIC_Model1\": model1.aic,\n",
    "    \"BIC_Model1\": model1.bic,\n",
    "    \"AIC_Model2\": model2.aic,\n",
    "    \"BIC_Model2\": model2.bic,\n",
    "    \"Log-Likelihood_Model1\": ll_model_1,\n",
    "    \"Log-Likelihood_Model1\": ll_model_2,\n",
    "    \"LR Statistic\": lr_statistic,\n",
    "    \"p-value\": p_value\n",
    "})\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df3a675a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Models \n",
    "model_results = {}\n",
    "results_list = []\n",
    "\n",
    "# Model 1: Fixed effect of Condition \n",
    "model1 = smf.mixedlm(\n",
    "    formula=\"Score ~ C(Condition) + C(Region)\",  \n",
    "    data=data_music,\n",
    "    groups=data_music[\"Channel\"]  \n",
    ").fit(reml=False)\n",
    "model_results[band_name] = {\"Model Condition + Region\": model1}\n",
    "\n",
    "\n",
    "# Model 2: Fixed effects of Condition and Region\n",
    "model2 = smf.mixedlm(\n",
    "    formula=\"Score ~ C(Condition) * C(Region)\",  \n",
    "    data=data_music,\n",
    "    groups=data_music[\"Channel\"]  \n",
    ").fit(reml=False)\n",
    "\n",
    "model_results[band_name][\"Model Condition * Region\"] = model2\n",
    "\n",
    "# Likelihood Ratio Test statistic\n",
    "ll_model_1 = model1.llf  \n",
    "ll_model_2 = model2.llf  \n",
    "num_params_model_1 = len(model1.params)\n",
    "num_params_model_2 = len(model2.params)\n",
    "\n",
    "lr_statistic = 2 * (ll_model_2 - ll_model_1)\n",
    "df_diff = num_params_model_2 - num_params_model_1\n",
    "p_value = 1 - stats.chi2.cdf(lr_statistic, df_diff)\n",
    "\n",
    "print(f\"Likelihood Ratio Test between Model 1 and Model 2: Statistic = {lr_statistic}, p-value = {p_value}\")\n",
    "\n",
    "results_list.append({\n",
    "    \"Stimuli\": \"music\", \n",
    "    \"Model1\": \"Condition + Region\",\n",
    "    \"Model2\": \"Condition * Region\",\n",
    "    \"AIC_Model1\": model1.aic,\n",
    "    \"BIC_Model1\": model1.bic,\n",
    "    \"AIC_Model2\": model2.aic,\n",
    "    \"BIC_Model2\": model2.bic,\n",
    "    \"Log-Likelihood_Model1\": ll_model_1,\n",
    "    \"Log-Likelihood_Model1\": ll_model_2,\n",
    "    \"LR Statistic\": lr_statistic,\n",
    "    \"p-value\": p_value\n",
    "})\n",
    "\n",
    "df_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff06390",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "model = smf.mixedlm(\"Score ~ C(Condition) * C(Region)\", data_music, groups=data_music[\"Channel\"]).fit(reml=False)\n",
    "#print(model.summary())\n",
    "\n",
    "results_list = []\n",
    "if model:\n",
    "    params = model.params\n",
    "    pvalues = model.pvalues\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    std_errs = model.bse  \n",
    "    tvalues = model.tvalues  \n",
    "    conf_int = model.conf_int()  \n",
    "    \n",
    "    for effect, coefficient in params.items():\n",
    "        t_value = tvalues.get(effect, None)\n",
    "        std_err = std_errs.get(effect, None)\n",
    "        lower_bound, upper_bound = conf_int.loc[effect].values\n",
    "        \n",
    "        results_list.append({\n",
    "            \"effect\": effect,\n",
    "            \"coef\": coefficient,  \n",
    "            \"SE\": std_err,        \n",
    "            \"p\": pvalues.get(effect, None),  \n",
    "            \"t\": t_value,        \n",
    "            \"[0.025\": lower_bound,  \n",
    "            \"0.975]\": upper_bound, \n",
    "            \"AIC\": aic,           \n",
    "            \"BIC\": bic,          \n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b32347",
   "metadata": {},
   "source": [
    "#### Model for speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for day, TRF in zip(['Day1', 'Day2'], [TRF1, TRF2]):\n",
    "    for condition in ['produce_speech', 'perceive_speech_produced']:\n",
    "        for pick in picks_H:\n",
    "            score = TRF[condition][pick]['score']\n",
    "            for sc in score:  \n",
    "                data.append({'Subject': 'BouNi', 'Condition': condition, 'Day': day, 'Channel': pick, 'Score': sc})\n",
    "\n",
    "data_speech = pd.DataFrame(data)\n",
    "\n",
    "data_speech['Condition'] = pd.Categorical(data_speech['Condition'], \n",
    "                                          categories=['produce_speech', 'perceive_speech_produced'],\n",
    "                                          ordered=True)\n",
    "data_speech['Region'] = data_speech['Channel'].map(channel_to_region)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original model \n",
    "model = smf.mixedlm(\"Score ~ C(Condition)\", data_speech, groups=data_speech[\"Channel\"]).fit(reml=False)\n",
    "#print(model.summary())\n",
    "\n",
    "results_list = []\n",
    "if model:\n",
    "    params = model.params\n",
    "    pvalues = model.pvalues\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    std_errs = model.bse  \n",
    "    tvalues = model.tvalues  \n",
    "    conf_int = model.conf_int()  \n",
    "    \n",
    "    for effect, coefficient in params.items():\n",
    "        t_value = tvalues.get(effect, None)\n",
    "        std_err = std_errs.get(effect, None)\n",
    "        lower_bound, upper_bound = conf_int.loc[effect].values\n",
    "        \n",
    "        results_list.append({\n",
    "            \"effect\": effect,\n",
    "            \"coef\": custom_round(coefficient),  \n",
    "            \"SE\": custom_round(std_err),        \n",
    "            \"p\": custom_round(pvalues.get(effect, None)),  \n",
    "            \"t\": custom_round(t_value),        \n",
    "            \"[0.025\": custom_round(lower_bound),  \n",
    "            \"0.975]\": custom_round(upper_bound), \n",
    "            #\"AIC\": custom_round(aic),           \n",
    "            #\"BIC\": custom_round(bic),          \n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dff9345",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Models \n",
    "model_results = {}\n",
    "results_list = []\n",
    "\n",
    "# Model 1: Fixed effect of Condition \n",
    "model1 = smf.mixedlm(\n",
    "    formula=\"Score ~ C(Condition)\",  \n",
    "    data=data_speech,\n",
    "    groups=data_speech[\"Channel\"]  \n",
    ").fit(reml=False)\n",
    "model_results[band_name] = {\"Model Condition\": model1}\n",
    "\n",
    "\n",
    "# Model 2: Fixed effects of Condition and Region\n",
    "model2 = smf.mixedlm(\n",
    "    formula=\"Score ~ C(Condition) + C(Region)\",  \n",
    "    data=data_speech,\n",
    "    groups=data_speech[\"Channel\"]  \n",
    ").fit(reml=False)\n",
    "\n",
    "model_results[band_name][\"Model Condition + Region\"] = model2\n",
    "\n",
    "# Likelihood Ratio Test statistic\n",
    "ll_model_1 = model1.llf  \n",
    "ll_model_2 = model2.llf  \n",
    "num_params_model_1 = len(model1.params)\n",
    "num_params_model_2 = len(model2.params)\n",
    "\n",
    "lr_statistic = 2 * (ll_model_2 - ll_model_1)\n",
    "df_diff = num_params_model_2 - num_params_model_1\n",
    "p_value = 1 - stats.chi2.cdf(lr_statistic, df_diff)\n",
    "\n",
    "print(f\"Likelihood Ratio Test between Model 1 and Model 2: Statistic = {lr_statistic}, p-value = {p_value}\")\n",
    "\n",
    "results_list.append({\n",
    "    \"Stimuli\": \"speech\", \n",
    "    \"Model1\": \"Condition\",\n",
    "    \"Model2\": \"Condition + Region\",\n",
    "    \"AIC_Model1\": model1.aic,\n",
    "    \"BIC_Model1\": model1.bic,\n",
    "    \"AIC_Model2\": model2.aic,\n",
    "    \"BIC_Model2\": model2.bic,\n",
    "    \"Log-Likelihood_Model1\": ll_model_1,\n",
    "    \"Log-Likelihood_Model1\": ll_model_2,\n",
    "    \"LR Statistic\": lr_statistic,\n",
    "    \"p-value\": p_value\n",
    "})\n",
    "\n",
    "df_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27f3b942",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare Models \n",
    "model_results = {}\n",
    "results_list = []\n",
    "\n",
    "# Model 1: Fixed effect of Condition \n",
    "model1 = smf.mixedlm(\n",
    "    formula=\"Score ~ C(Condition) + C(Region)\",  \n",
    "    data=data_speech,\n",
    "    groups=data_speech[\"Channel\"]  \n",
    ").fit(reml=False)\n",
    "model_results[band_name] = {\"Model Condition + Region\": model1}\n",
    "\n",
    "\n",
    "# Model 2: Fixed effects of Condition and Region\n",
    "model2 = smf.mixedlm(\n",
    "    formula=\"Score ~ C(Condition) * C(Region)\",  \n",
    "    data=data_speech,\n",
    "    groups=data_speech[\"Channel\"]  \n",
    ").fit(reml=False)\n",
    "\n",
    "model_results[band_name][\"Model Condition * Region\"] = model2\n",
    "\n",
    "# Likelihood Ratio Test statistic\n",
    "ll_model_1 = model1.llf  \n",
    "ll_model_2 = model2.llf  \n",
    "num_params_model_1 = len(model1.params)\n",
    "num_params_model_2 = len(model2.params)\n",
    "\n",
    "lr_statistic = 2 * (ll_model_2 - ll_model_1)\n",
    "df_diff = num_params_model_2 - num_params_model_1\n",
    "p_value = 1 - stats.chi2.cdf(lr_statistic, df_diff)\n",
    "\n",
    "print(f\"Likelihood Ratio Test between Model 1 and Model 2: Statistic = {lr_statistic}, p-value = {p_value}\")\n",
    "\n",
    "results_list.append({\n",
    "    \"Stimuli\": \"speech\", \n",
    "    \"Model1\": \"Condition + Region\",\n",
    "    \"Model2\": \"Condition * Region\",\n",
    "    \"AIC_Model1\": model1.aic,\n",
    "    \"BIC_Model1\": model1.bic,\n",
    "    \"AIC_Model2\": model2.aic,\n",
    "    \"BIC_Model2\": model2.bic,\n",
    "    \"Log-Likelihood_Model1\": ll_model_1,\n",
    "    \"Log-Likelihood_Model1\": ll_model_2,\n",
    "    \"LR Statistic\": lr_statistic,\n",
    "    \"p-value\": p_value\n",
    "})\n",
    "\n",
    "df_results = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34399891",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "model = smf.mixedlm(\"Score ~ C(Condition) * C(Region)\", data_speech, groups=data_speech[\"Channel\"]).fit(reml=False)\n",
    "#print(model.summary())\n",
    "\n",
    "results_list = []\n",
    "if model:\n",
    "    params = model.params\n",
    "    pvalues = model.pvalues\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    std_errs = model.bse  \n",
    "    tvalues = model.tvalues  \n",
    "    conf_int = model.conf_int()  \n",
    "    \n",
    "    for effect, coefficient in params.items():\n",
    "        t_value = tvalues.get(effect, None)\n",
    "        std_err = std_errs.get(effect, None)\n",
    "        lower_bound, upper_bound = conf_int.loc[effect].values\n",
    "        \n",
    "        results_list.append({\n",
    "            \"effect\": effect,\n",
    "            \"coef\": coefficient,  \n",
    "            \"SE\": std_err,        \n",
    "            \"p\": pvalues.get(effect, None),  \n",
    "            \"t\": t_value,        \n",
    "            \"[0.025\": lower_bound,  \n",
    "            \"0.975]\": upper_bound, \n",
    "            \"AIC\": aic,           \n",
    "            \"BIC\": bic,          \n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70236cfb",
   "metadata": {},
   "source": [
    "## Speech and Music Repetition: First Hearing - Second Hearing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TRF for control conditions\n",
    "TRF_control = {}\n",
    "for condition in condition_list_control: \n",
    "        TRF_control[condition] = {}\n",
    "        for pick in picks_H: \n",
    "                TRF_control[condition][pick] = {}\n",
    "                TRF_control[condition][pick]['score'] = TRF1[condition][pick]['score']\n",
    "                TRF_control[condition][pick]['coefs'] = TRF1[condition][pick]['coefs']\n",
    "                TRF_control[condition][pick]['predicted_Y'] = TRF1[condition][pick]['predicted_Y']\n",
    "                TRF_control[condition][pick]['times'] = TRF1[condition][pick]['times'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c614205",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "channel_assignment = [0, 6, 8, 12, len(picks_H)]\n",
    "\n",
    "for n, contrast in enumerate(contrasts_control):\n",
    "    if \"music\" in contrast[0]: \n",
    "        color_prod = 'purple'\n",
    "        color_perc = 'plum'\n",
    "    elif \"speech\" in contrast[0]: \n",
    "        color_prod = '#008000'\n",
    "        color_perc = '#90EE90'\n",
    "\n",
    "    data_firsthearing = np.array([TRF_control[contrast[0]][pick]['score'] for pick in picks_H])\n",
    "    data_secondhearing = np.array([TRF_control[contrast[1]][pick]['score'] for pick in picks_H])\n",
    "\n",
    "    mean_firsthearing = np.mean(data_firsthearing, axis=1)\n",
    "    se_firsthearing = np.std(data_firsthearing, axis=1, ddof=1) / np.sqrt(len(data_firsthearing[0]))\n",
    "\n",
    "    mean_secondhearing = np.mean(data_secondhearing, axis=1)\n",
    "    se_secondhearing = np.std(data_secondhearing, axis=1, ddof=1) / np.sqrt(len(data_secondhearing[0]))\n",
    "\n",
    "    # t-test\n",
    "    t, p = stats.stats.ttest_rel(data_firsthearing.T, data_secondhearing.T)\n",
    "    p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)    \n",
    "    significance_threshold = 0.05\n",
    "    significant_channels = np.where(p_corrected < significance_threshold)[0]\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax2 = ax.twinx()  \n",
    "  \n",
    "    ## plot means, se  \n",
    "    for c in range(len(channel_assignment)-1):\n",
    "        ax.errorbar(mean_firsthearing[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_firsthearing[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_prod, capsize=8)\n",
    "        ax.errorbar(mean_secondhearing[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_secondhearing[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_perc, capsize=8)\n",
    "    \n",
    "\n",
    "    ## plot significant differences\n",
    "    for s in range(len(picks_H)):\n",
    "        if p_corrected[s] < 0.05:\n",
    "            x_pos = - 0.025\n",
    "            y_pos = s - 0.15\n",
    "            ax.text(x_pos, y_pos, \"*\", fontsize=20, color='black', ha='center', va='center', zorder=3)\n",
    "\n",
    "    ax.set_xlabel('\\n r$^2$-coefficients', fontsize=16)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.set_ylabel('Channels', fontsize=16)\n",
    "    ax.set_xlim([-0.05, 0.42])\n",
    "    ax.set_yticks(np.arange(len(picks_H)))\n",
    "    ax.set_yticklabels(picks_H, fontsize=14)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "        ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1)\n",
    "    ax2.set_ylim(ax.get_ylim()) \n",
    "    channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "    ax2.set_yticks(channel_midpoints)  \n",
    "    ax2.set_yticklabels(brain_label, size=14, va='center')  \n",
    "\n",
    "    legend_handles = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=color_prod, markersize=15, label='First Hearing'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=color_perc, markersize=15, label='Second Hearing')\n",
    "    ]\n",
    "\n",
    "    ax.legend(handles=legend_handles, fontsize=13) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Mixed Effect Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e325b19",
   "metadata": {},
   "source": [
    "### Model for music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for condition in ['perceive_music_new', 'perceive_music_newrepetition']:\n",
    "    for pick in picks_H:\n",
    "        score = TRF_control[condition][pick]['score']\n",
    "        for sc in score:  \n",
    "            data.append({'Subject': 'BouNi', 'Condition': condition, 'Channel': pick, 'Score': sc})\n",
    "\n",
    "data_music = pd.DataFrame(data)\n",
    "\n",
    "data_music['Condition'] = pd.Categorical(data_music['Condition'], \n",
    "                                          categories=['perceive_music_new', 'perceive_music_newrepetition'],\n",
    "                                          ordered=True)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Score ~ C(Condition)\", data_music, groups=data_music[\"Channel\"]).fit(reml=False)\n",
    "#print(model.summary())\n",
    "\n",
    "results_list = []\n",
    "if model:\n",
    "    params = model.params\n",
    "    pvalues = model.pvalues\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    std_errs = model.bse  \n",
    "    tvalues = model.tvalues  \n",
    "    conf_int = model.conf_int()  \n",
    "    \n",
    "    for effect, coefficient in params.items():\n",
    "        t_value = tvalues.get(effect, None)\n",
    "        std_err = std_errs.get(effect, None)\n",
    "        lower_bound, upper_bound = conf_int.loc[effect].values\n",
    "        \n",
    "        results_list.append({\n",
    "            \"effect\": effect,\n",
    "            \"coef\": custom_round(coefficient),  \n",
    "            \"SE\": custom_round(std_err),        \n",
    "            \"p\": custom_round(pvalues.get(effect, None)),  \n",
    "            \"t\": custom_round(t_value),        \n",
    "            \"[0.025\": custom_round(lower_bound),  \n",
    "            \"0.975]\": custom_round(upper_bound), \n",
    "            #\"AIC\": custom_round(aic),           \n",
    "            #\"BIC\": custom_round(bic),          \n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973dd582",
   "metadata": {},
   "source": [
    "#### Model for speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for condition in ['perceive_speech_new', 'perceive_speech_newrepetition']:\n",
    "    for pick in picks_H:\n",
    "        score = TRF_control[condition][pick]['score']\n",
    "        for sc in score:  \n",
    "            data.append({'Subject': 'BouNi', 'Condition': condition, 'Channel': pick, 'Score': sc})\n",
    "\n",
    "data_speech = pd.DataFrame(data)\n",
    "\n",
    "data_speech['Condition'] = pd.Categorical(data_speech['Condition'], \n",
    "                                          categories=['perceive_speech_new', 'perceive_speech_newrepetition'],\n",
    "                                          ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05698127",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = smf.mixedlm(\"Score ~ C(Condition)\", data_speech, groups=data_speech[\"Channel\"]).fit(reml=False)\n",
    "\n",
    "results_list = []\n",
    "if model:\n",
    "    params = model.params\n",
    "    pvalues = model.pvalues\n",
    "    aic = model.aic\n",
    "    bic = model.bic\n",
    "    std_errs = model.bse  \n",
    "    tvalues = model.tvalues  \n",
    "    conf_int = model.conf_int()  \n",
    "    \n",
    "    for effect, coefficient in params.items():\n",
    "        t_value = tvalues.get(effect, None)\n",
    "        std_err = std_errs.get(effect, None)\n",
    "        lower_bound, upper_bound = conf_int.loc[effect].values\n",
    "        \n",
    "        results_list.append({\n",
    "            \"effect\": effect,\n",
    "            \"coef\": custom_round(coefficient),  \n",
    "            \"SE\": custom_round(std_err),        \n",
    "            \"p\": custom_round(pvalues.get(effect, None)),  \n",
    "            \"t\": custom_round(t_value),        \n",
    "            \"[0.025\": custom_round(lower_bound),  \n",
    "            \"0.975]\": custom_round(upper_bound), \n",
    "            #\"AIC\": custom_round(aic),           \n",
    "            #\"BIC\": custom_round(bic),          \n",
    "        })\n",
    "\n",
    "results_df = pd.DataFrame(results_list)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ins_paper",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
