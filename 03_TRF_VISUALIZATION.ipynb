{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf62157",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc \n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd0b5b33",
   "metadata": {},
   "source": [
    "# Temporal Response Function (TRF) - Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5f993e9",
   "metadata": {},
   "source": [
    "### Modules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79bede75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mne \n",
    "import pickle\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "from matplotlib.lines import Line2D\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from scipy import stats\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "from statsmodels.stats.multitest import multipletests\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8113a134",
   "metadata": {},
   "source": [
    "### Define dictionaries, subject, & conditions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set path to main folder\n",
    "%cd ~/\n",
    "%pwd\n",
    "\n",
    "# path to data files\n",
    "data_path = \"/Volumes/Elements/data_mne/\"\n",
    "\n",
    "# subject \n",
    "subj = ['Bou_Ni'] \n",
    "sub_idx = 0 # subject number\n",
    "\n",
    "# frequency band \n",
    "band_name = \"Low Frequencies\"\n",
    "band = \"deltatheta\" \n",
    "\n",
    "# list of conditions\n",
    "condition_list = ['produce_music', 'perceive_music_produced', 'produce_speech', 'perceive_speech_produced']\n",
    "contrasts = [[\"produce_music\", \"perceive_music_produced\"], [\"produce_speech\", \"perceive_speech_produced\"]]\n",
    "pairs = [[\"music\",\"produce_music\"], [\"music\", \"perceive_music_produced\"], [\"speech\", \"produce_speech\"], [\"speech\", \"perceive_speech_produced\"]]\n",
    "contrasts = [[\"produce_music\", \"perceive_music_produced\"], [\"produce_speech\", \"perceive_speech_produced\"]]\n",
    "condition_names = [\"Music \\n Production\", \"Music \\n Perception\", \"Speech \\n Production\", \"Speech \\n Perception\"]\n",
    "contrast_names = [\"Music Production And Music Perception\", \"Speech Production and Speech Perception\"]\n",
    "\n",
    "condition_list_control = ['perceive_music_new', 'perceive_music_newrepetition', 'perceive_speech_new', 'perceive_speech_newrepetition']\n",
    "contrasts_control = [[\"perceive_music_new\", \"perceive_music_newrepetition\"], [\"perceive_speech_new\", \"perceive_speech_newrepetition\"]]\n",
    "pairs_control = [[\"perceive_music_new\", \"perceive_music_newrepetition\"], [\"speech_new\", \"perceive_speech_new\"], [\"speech_new\", \"perceive_speech_newrepetition\"]]\n",
    "condition_names_control = [\"Music \\n Perception \\n Control\", \"Music \\n Perception \\n Control Repetition\", \"Speech \\n Perception \\n Control\", \"Speech \\n Perception \\n Control Repetition\", ]\n",
    "contrast_names_control = [\"Music First Hearing And Music Second Hearing\", \"Speech First Hearing and Speech Second Hearing\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d60070d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# recording path \n",
    "recording_path = data_path + subj[sub_idx] + \"/wavfiles/\"\n",
    "print(recording_path)\n",
    "\n",
    "# matlabfiles path \n",
    "features_path = data_path + subj[sub_idx] + \"/stimulusfeatures/\"\n",
    "print(features_path)\n",
    "\n",
    "# dictionary path \n",
    "dictionary_path = data_path + subj[sub_idx] + \"/dictionary\"\n",
    "\n",
    "# plot path \n",
    "plot_path = data_path + subj[sub_idx] + \"/plots/Temporal-Response-Function-Plots/\"\n",
    "print(plot_path)\n",
    "\n",
    "# freesurfer path \n",
    "fs_path = data_path + subj[sub_idx] + '/freesurfer/Bou_Ni/elec_recon/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3c6aedf",
   "metadata": {},
   "source": [
    "### Load raw data and channel information "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b51fcc0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# load in raw \n",
    "raw = {}\n",
    "\n",
    "for condition in condition_list:\n",
    "    preprocessed_path = data_path + subj[sub_idx] + \"/preprocessed/\" + condition + \"/\"\n",
    "    \n",
    "    for files in os.listdir(preprocessed_path):\n",
    "        filename = \"day1_bipolar_raw_preprocessed.fif\"\n",
    "        if filename in files:\n",
    "            path = preprocessed_path + files + '/'\n",
    "            raw[condition] =  mne.io.read_raw_fif(path, preload=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bdbf60a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# channel names (picks)\n",
    "picks = raw['produce_music'].ch_names\n",
    "\n",
    "# define channels in the auditory cortex \n",
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "print('channels in auditory cortex: ', picks_H)\n",
    "\n",
    "# assign channels to LH and RH primary and non-primary auditory cortex \n",
    "picks_primary_RH = ['H5-H6', 'H6-H7', 'H7-H8', 'H8-H9', 'H9-H10', 'H10-H11']\n",
    "picks_primary_LH = [ \"H'5-H'6\", \"H'6-H'7\", \"H'7-H'8\", \"H'8-H'9\"]\n",
    "picks_nonprimary_RH = ['H11-H12', 'H12-H13']\n",
    "picks_nonprimary_LH = [ \"H'9-H'10\", \"H'10-H'11\", \"H'11-H'12\"]\n",
    "\n",
    "picks_subset = [picks_primary_LH, picks_nonprimary_LH, picks_primary_RH, picks_nonprimary_RH,]\n",
    "picks_subset_names = [\"Left Primary Auditory Cortex\", \"Left Associative Auditory Cortex\", \"Right Primary Auditory Cortex\", \"Right Associative Auditory Cortex\"] \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b50adc62",
   "metadata": {},
   "source": [
    "### Load accoustic regressors and TRF data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce551ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# regressors  \n",
    "with open(f\"{dictionary_path}/TRF_0906/TRF_regressors_deltatheta_day1.pickle\", 'rb') as f:\n",
    "        regressors1 = pickle.load(f)\n",
    "\n",
    "with open(f\"{dictionary_path}/TRF_0906/TRF_regressors_deltatheta_day2.pickle\", 'rb') as f:\n",
    "        regressors2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TRF crossvalidated data for H-channels \n",
    "with open(f\"{dictionary_path}/TRF_0906/TRF_results_deltatheta_day1_crossvalidate.pickle\", 'rb') as f:\n",
    "        TRF1 = pickle.load(f)\n",
    "\n",
    "with open(f\"{dictionary_path}/TRF_0906/TRF_results_deltatheta_day2_crossvalidate.pickle\", 'rb') as f:\n",
    "        TRF2 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "faa33be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# parameters \n",
    "labels = regressors1['music'][1]\n",
    "fs = 100\n",
    "scoring = 'r2'\n",
    "tw = [-0.2, 0.5]                                            #in sec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39cf2ef8",
   "metadata": {},
   "source": [
    "# Compare conditions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b31d25a",
   "metadata": {},
   "source": [
    "## Self Produced Speech and Music: Production - Perception "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# concatenate data from two days\n",
    "TRF = {}\n",
    "for condition in condition_list: \n",
    "        TRF[condition] = {}\n",
    "        print(condition)\n",
    "        for pick in picks_H: \n",
    "                TRF[condition][pick] = {}\n",
    "                TRF[condition][pick]['score'] = np.concatenate((TRF1[condition][pick]['score'], TRF2[condition][pick]['score']), axis=0)\n",
    "                TRF[condition][pick]['coefs'] = np.concatenate((TRF1[condition][pick]['coefs'], TRF2[condition][pick]['coefs']), axis=0)\n",
    "                TRF[condition][pick]['predicted_Y'] = np.concatenate((TRF1[condition][pick]['predicted_Y'], TRF2[condition][pick]['predicted_Y']), axis=0)\n",
    "                TRF[condition][pick]['times'] = TRF1[condition][pick]['times'] # same across two days \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TRF for main analysis for day1\n",
    "TRF_day1 = {}\n",
    "for condition in condition_list: \n",
    "        TRF_day1[condition] = {}\n",
    "        print(condition)\n",
    "        for pick in picks_H: \n",
    "                TRF_day1[condition][pick] = {}\n",
    "                TRF_day1[condition][pick]['score'] = TRF1[condition][pick]['score']\n",
    "                TRF_day1[condition][pick]['coefs'] = TRF1[condition][pick]['coefs']\n",
    "                TRF_day1[condition][pick]['predicted_Y'] = TRF1[condition][pick]['predicted_Y']\n",
    "                TRF_day1[condition][pick]['times'] = TRF1[condition][pick]['times'] \n",
    "\n",
    "# load TRF for main analysis for day1\n",
    "TRF_day2 = {}\n",
    "for condition in condition_list: \n",
    "        TRF_day2[condition] = {}\n",
    "        print(condition)\n",
    "        for pick in picks_H: \n",
    "                TRF_day2[condition][pick] = {}\n",
    "                TRF_day2[condition][pick]['score'] = TRF2[condition][pick]['score']\n",
    "                TRF_day2[condition][pick]['coefs'] = TRF2[condition][pick]['coefs']\n",
    "                TRF_day2[condition][pick]['predicted_Y'] = TRF2[condition][pick]['predicted_Y']\n",
    "                TRF_day2[condition][pick]['times'] = TRF2[condition][pick]['times'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TRF shape \n",
    "pick = 'H5-H6'\n",
    "i_reg = 5 # loadness derivative\n",
    "colors = ['purple', 'plum', '#008000', '#90EE90']\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(8,6))\n",
    "fig.subplots_adjust(top=0.85)\n",
    "\n",
    "for n, condition in enumerate(condition_list):\n",
    "    times = TRF[condition][pick]['times']\n",
    "\n",
    "    coefs_pick = TRF[condition][pick][\"coefs\"]\n",
    "    coefs_mean = np.mean(coefs_pick[:, i_reg, :], axis=0)\n",
    "    ax.plot(times, coefs_mean, label=condition_names[n], color=colors[n], linewidth=3)\n",
    "\n",
    "\n",
    "ax.hlines(0, times[0], times[1], colors='gray', linestyles='--')\n",
    "ax.vlines(0, np.min(values), np.max(values), color='black', linestyle='--', alpha=0.5)  # t = 0\n",
    "ax.vlines(0.1, np.min(values), np.max(values), color='gray', linestyle='--', alpha=0.5)  # t = 100ms\n",
    "\n",
    "ax.legend(loc='upper right', prop={'size': 8})\n",
    "ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "ax.set_xlabel(\"Time (s)\")\n",
    "ax.set_ylabel(\"Amplitude\")\n",
    "# plt.savefig(plot_path + f\"TRF_efferencecopy_averagedchannels_{labels[i_reg]}_deltatheta_{day}_trf-plot.jpg\", bbox_inches='tight')\n",
    "plt.show()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "channel_assignment = [0, 6, 8, 12, len(picks_H)]\n",
    "\n",
    "for n, contrast in enumerate(contrasts):\n",
    "    print(contrast)\n",
    "    if \"music\" in contrast[0]: \n",
    "        color_prod = 'purple'\n",
    "        color_perc = 'plum'\n",
    "    elif \"speech\" in contrast[0]: \n",
    "        color_prod = '#008000'\n",
    "        color_perc = '#90EE90'\n",
    "\n",
    "        \n",
    "    data_production = np.array([TRF[contrast[0]][pick]['score'] for pick in picks_H])\n",
    "    data_perception = np.array([TRF[contrast[1]][pick]['score'] for pick in picks_H])\n",
    "\n",
    "    mean_production = np.mean(data_production, axis=1)\n",
    "    se_production = np.std(data_production, axis=1, ddof=1) / np.sqrt(len(data_production[0]))\n",
    "\n",
    "    mean_perception = np.mean(data_perception, axis=1)\n",
    "    se_perception = np.std(data_perception, axis=1, ddof=1) / np.sqrt(len(data_perception[0]))\n",
    "\n",
    "    # t-test\n",
    "    t, p = stats.stats.ttest_rel(data_production.T, data_perception.T)\n",
    "    p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)    \n",
    "    print(p_corrected < 0.05)\n",
    "    significance_threshold = 0.05\n",
    "    significant_channels = np.where(p_corrected < significance_threshold)[0]\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax2 = ax.twinx()  \n",
    "\n",
    "    ## plot data points \n",
    "    jitter_width = 0.15 \n",
    "    for i in range(len(data_production)):\n",
    "        jitter_prod = np.random.uniform(-jitter_width, jitter_width, size=len(data_production[i]))\n",
    "        jitter_perc = np.random.uniform(-jitter_width, jitter_width, size=len(data_perception[i]))\n",
    "\n",
    "        ax.scatter(data_production[i], np.full(len(data_production[i]), i) + jitter_prod,\n",
    "                alpha=0.3, color=color_prod, s=10)\n",
    "        ax.scatter(data_perception[i], np.full(len(data_perception[i]), i) + jitter_perc,\n",
    "                alpha=0.3, color=color_perc, s=10)\n",
    "        \n",
    "    ## plot means, se  \n",
    "    for c in range(len(channel_assignment)-1):\n",
    "        ax.errorbar(mean_production[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_production[channel_assignment[c]:channel_assignment[c+1]], marker='o', linestyle='-', color=color_prod, capsize=8)\n",
    "        ax.errorbar(mean_perception[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_perception[channel_assignment[c]:channel_assignment[c+1]], marker='s', linestyle='-', color=color_perc, capsize=8)\n",
    "    \n",
    "\n",
    "    ## plot significant differences\n",
    "    for s in range(len(picks_H)):\n",
    "        if p_corrected[s] < 0.05:\n",
    "            x_pos = -0.225\n",
    "            y_pos = s - 0.15\n",
    "            ax.text(x_pos, y_pos, \"*\", fontsize=20, color='black', ha='center', va='center', zorder=3)\n",
    "\n",
    "    ax.set_xlabel('r$^2$ Coefficients', fontsize=14)\n",
    "    ax.set_ylabel('Channels', fontsize=14)\n",
    "    ax.set_xlim([-0.25, 0.55])\n",
    "    ax.set_yticks(np.arange(len(picks_H)))\n",
    "    ax.set_yticklabels(picks_H, fontsize=10)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "        ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1)\n",
    "    ax2.set_ylim(ax.get_ylim()) \n",
    "    channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "    ax2.set_yticks(channel_midpoints)  \n",
    "    ax2.set_yticklabels(brain_label, size=10, va='center')  \n",
    "\n",
    "    ax.legend([\"Production\", \"Perception\"])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "channel_assignment = [0, 6, 8, 12, len(picks_H)]\n",
    "\n",
    "for n, contrast in enumerate(contrasts):\n",
    "    print(contrast)\n",
    "    if \"music\" in contrast[0]: \n",
    "        color_prod = 'purple'\n",
    "        color_perc = 'plum'\n",
    "    elif \"speech\" in contrast[0]: \n",
    "        color_prod = '#008000'\n",
    "        color_perc = '#90EE90'\n",
    "\n",
    "        \n",
    "    data_production = np.array([TRF[contrast[0]][pick]['score'] for pick in picks_H])\n",
    "    data_perception = np.array([TRF[contrast[1]][pick]['score'] for pick in picks_H])\n",
    "\n",
    "    mean_production = np.mean(data_production, axis=1)\n",
    "    se_production = np.std(data_production, axis=1, ddof=1) / np.sqrt(len(data_production[0]))\n",
    "\n",
    "    mean_perception = np.mean(data_perception, axis=1)\n",
    "    se_perception = np.std(data_perception, axis=1, ddof=1) / np.sqrt(len(data_perception[0]))\n",
    "\n",
    "    # t-test\n",
    "    t, p = stats.stats.ttest_rel(data_production.T, data_perception.T)\n",
    "    p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)    \n",
    "    print(p_corrected < 0.05)\n",
    "    significance_threshold = 0.05\n",
    "    significant_channels = np.where(p_corrected < significance_threshold)[0]\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax2 = ax.twinx()  \n",
    "  \n",
    "    ## plot means, se  \n",
    "    for c in range(len(channel_assignment)-1):\n",
    "        ax.errorbar(mean_production[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_production[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_prod, capsize=8)\n",
    "        ax.errorbar(mean_perception[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_perception[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_perc, capsize=8)\n",
    "    \n",
    "    ## plot significant differences\n",
    "    for s in range(len(picks_H)):\n",
    "        if p_corrected[s] < 0.05:\n",
    "            x_pos = - 0.025\n",
    "            y_pos = s - 0.15\n",
    "            ax.text(x_pos, y_pos, \"*\", fontsize=20, color='black', ha='center', va='center', zorder=3)\n",
    "\n",
    "    #ax.set_title(f'r$^2$ Coeffients for {contrast_names[n]} \\n', fontsize=16)\n",
    "    ax.set_xlabel('\\n r$^2$-coefficients', fontsize=16)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.set_ylabel('Channels', fontsize=16)\n",
    "    ax.set_xlim([-0.05, 0.42])\n",
    "    ax.set_yticks(np.arange(len(picks_H)))\n",
    "    ax.set_yticklabels(picks_H, fontsize=14)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "        ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1)\n",
    "    ax2.set_ylim(ax.get_ylim()) \n",
    "    channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "    ax2.set_yticks(channel_midpoints)  \n",
    "    ax2.set_yticklabels(brain_label, size=14, va='center')  \n",
    "\n",
    "    legend_handles = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=color_prod, markersize=15, label='Production'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=color_perc, markersize=15, label='Perception')\n",
    "    ]\n",
    "\n",
    "    ax.legend(handles=legend_handles, fontsize=13) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot seperatly for the days \n",
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "channel_assignment = [0, 6, 8, 12, len(picks_H)]\n",
    "\n",
    "for day, TRF in zip(['Day1', 'Day2'], [TRF1, TRF2]):\n",
    "    for n, contrast in enumerate(contrasts):\n",
    "        print(contrast)\n",
    "        if \"music\" in contrast[0]: \n",
    "            color_prod = 'purple'\n",
    "            color_perc = 'plum'\n",
    "        elif \"speech\" in contrast[0]: \n",
    "            color_prod = '#008000'\n",
    "            color_perc = '#90EE90'\n",
    "\n",
    "        data_production = np.array([TRF[contrast[0]][pick]['score'] for pick in picks_H])\n",
    "        data_perception = np.array([TRF[contrast[1]][pick]['score'] for pick in picks_H])\n",
    "\n",
    "        mean_production = np.mean(data_production, axis=1)\n",
    "        se_production = np.std(data_production, axis=1, ddof=1) / np.sqrt(len(data_production[0]))\n",
    "\n",
    "        mean_perception = np.mean(data_perception, axis=1)\n",
    "        se_perception = np.std(data_perception, axis=1, ddof=1) / np.sqrt(len(data_perception[0]))\n",
    "\n",
    "        # t-test\n",
    "        t, p = stats.stats.ttest_rel(data_production.T, data_perception.T)\n",
    "        p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)    \n",
    "        print(p_corrected < 0.05)\n",
    "        significance_threshold = 0.05\n",
    "        significant_channels = np.where(p_corrected < significance_threshold)[0]\n",
    "\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax2 = ax.twinx()  \n",
    "\n",
    "        ## plot data points \n",
    "        jitter_width = 0.15 \n",
    "        for i in range(len(data_production)):\n",
    "            jitter_prod = np.random.uniform(-jitter_width, jitter_width, size=len(data_production[i]))\n",
    "            jitter_perc = np.random.uniform(-jitter_width, jitter_width, size=len(data_perception[i]))\n",
    "\n",
    "            ax.scatter(data_production[i], np.full(len(data_production[i]), i) + jitter_prod,\n",
    "                    alpha=0.3, color=color_prod, s=10)\n",
    "            ax.scatter(data_perception[i], np.full(len(data_perception[i]), i) + jitter_perc,\n",
    "                    alpha=0.3, color=color_perc, s=10)\n",
    "            \n",
    "        ## plot means, se  \n",
    "        for c in range(len(channel_assignment)-1):\n",
    "            ax.errorbar(mean_production[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_production[channel_assignment[c]:channel_assignment[c+1]], marker='o', linestyle='-', color=color_prod, capsize=8)\n",
    "            ax.errorbar(mean_perception[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_perception[channel_assignment[c]:channel_assignment[c+1]], marker='s', linestyle='-', color=color_perc, capsize=8)\n",
    "\n",
    "        ## plot significant differences\n",
    "        for s in range(len(picks_H)):\n",
    "            if p_corrected[s] < 0.05:\n",
    "                x_pos = -0.225\n",
    "                y_pos = s - 0.15\n",
    "                ax.text(x_pos, y_pos, \"*\", fontsize=20, color='black', ha='center', va='center', zorder=3)\n",
    "\n",
    "        #ax.set_title(f'r$^2$ Coeffients for {contrast_names[n]} for {day} \\n', fontsize=16)\n",
    "        ax.set_xlabel('r$^2$ Coefficients', fontsize=14)\n",
    "        ax.set_ylabel('Channels', fontsize=14)\n",
    "        ax.set_xlim([-0.25, 0.55])\n",
    "        ax.set_yticks(np.arange(len(picks_H)))\n",
    "        ax.set_yticklabels(picks_H, fontsize=10)\n",
    "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "            ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1)\n",
    "        ax2.set_ylim(ax.get_ylim()) \n",
    "        channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "        ax2.set_yticks(channel_midpoints)  \n",
    "        ax2.set_yticklabels(brain_label, size=10, va='center')  \n",
    "\n",
    "        ax.legend([\"Production\", \"Perception\"])\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4beba24e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot seperatly for the days \n",
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "channel_assignment = [0, 6, 8, 12, len(picks_H)]\n",
    "\n",
    "for day, TRF in zip(['Day1', 'Day2'], [TRF1, TRF2]):\n",
    "    for n, contrast in enumerate(contrasts):\n",
    "        print(contrast)\n",
    "        if \"music\" in contrast[0]: \n",
    "            color_prod = 'purple'\n",
    "            color_perc = 'plum'\n",
    "        elif \"speech\" in contrast[0]: \n",
    "            color_prod = '#008000'\n",
    "            color_perc = '#90EE90'\n",
    "\n",
    "        data_production = np.array([TRF[contrast[0]][pick]['score'] for pick in picks_H])\n",
    "        data_perception = np.array([TRF[contrast[1]][pick]['score'] for pick in picks_H])\n",
    "\n",
    "        mean_production = np.mean(data_production, axis=1)\n",
    "        se_production = np.std(data_production, axis=1, ddof=1) / np.sqrt(len(data_production[0]))\n",
    "\n",
    "        mean_perception = np.mean(data_perception, axis=1)\n",
    "        se_perception = np.std(data_perception, axis=1, ddof=1) / np.sqrt(len(data_perception[0]))\n",
    "\n",
    "        # t-test\n",
    "        t, p = stats.stats.ttest_rel(data_production.T, data_perception.T)\n",
    "        p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)    \n",
    "        print(p_corrected < 0.05)\n",
    "        significance_threshold = 0.05\n",
    "        significant_channels = np.where(p_corrected < significance_threshold)[0]\n",
    "\n",
    "        # plot\n",
    "        fig, ax = plt.subplots(figsize=(12, 8))\n",
    "        ax2 = ax.twinx()  \n",
    "    \n",
    "        ## plot means, se  \n",
    "        for c in range(len(channel_assignment)-1):\n",
    "            ax.errorbar(mean_production[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_production[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_prod, capsize=8)\n",
    "            ax.errorbar(mean_perception[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_perception[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_perc, capsize=8)\n",
    "        \n",
    "\n",
    "        ## plot significant differences\n",
    "        for s in range(len(picks_H)):\n",
    "            if p_corrected[s] < 0.05:\n",
    "                x_pos = - 0.025\n",
    "                y_pos = s - 0.15\n",
    "                ax.text(x_pos, y_pos, \"*\", fontsize=20, color='black', ha='center', va='center', zorder=3)\n",
    "\n",
    "        ax.set_xlabel('\\n r$^2$-coefficients', fontsize=16)\n",
    "        ax.tick_params(axis='x', labelsize=16)\n",
    "        ax.set_ylabel('Channels', fontsize=16)\n",
    "        ax.set_xlim([-0.05, 0.42])\n",
    "        ax.set_yticks(np.arange(len(picks_H)))\n",
    "        ax.set_yticklabels(picks_H, fontsize=14)\n",
    "        ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "        for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "            ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1)\n",
    "        ax2.set_ylim(ax.get_ylim()) \n",
    "        channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "        ax2.set_yticks(channel_midpoints)  \n",
    "        ax2.set_yticklabels(brain_label, size=14, va='center')  \n",
    "\n",
    "        legend_handles = [\n",
    "            Line2D([0], [0], marker='o', color='w', markerfacecolor=color_prod, markersize=15, label='Production'),\n",
    "            Line2D([0], [0], marker='o', color='w', markerfacecolor=color_perc, markersize=15, label='Perception')\n",
    "        ]\n",
    "\n",
    "        ax.legend(handles=legend_handles, fontsize=13) \n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mixed linear effects model \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a77adc3b",
   "metadata": {},
   "source": [
    "#### Model for music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for day, TRF in zip(['Day1', 'Day2'], [TRF1, TRF2]):\n",
    "    for condition in ['produce_music', 'perceive_music_produced']:\n",
    "        for pick in picks_H:\n",
    "            score = TRF[condition][pick]['score']\n",
    "            for sc in score:  \n",
    "                data.append({'Subject': 'BouNi', 'Condition': condition, 'Day': day, 'Channel': pick, 'Score': sc})\n",
    "\n",
    "data_music = pd.DataFrame(data)\n",
    "\n",
    "data_music['Condition'] = pd.Categorical(data_music['Condition'], \n",
    "                                          categories=['produce_music', 'perceive_music_produced'],\n",
    "                                          ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Score ~ C(Condition) + C(Day) + C(Condition) * C(Day)\", data_music, groups=data_music[\"Subject\"])\n",
    "result = model.fit()\n",
    "print(\"music\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79b32347",
   "metadata": {},
   "source": [
    "#### Model for speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for day, TRF in zip(['Day1', 'Day2'], [TRF1, TRF2]):\n",
    "    for condition in ['produce_speech', 'perceive_speech_produced']:\n",
    "        for pick in picks_H:\n",
    "            score = TRF[condition][pick]['score']\n",
    "            for sc in score:  \n",
    "                data.append({'Subject': 'BouNi', 'Condition': condition, 'Day': day, 'Channel': pick, 'Score': sc})\n",
    "\n",
    "data_speech = pd.DataFrame(data)\n",
    "\n",
    "data_speech['Condition'] = pd.Categorical(data_speech['Condition'], \n",
    "                                          categories=['produce_speech', 'perceive_speech_produced'],\n",
    "                                          ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Score ~ C(Condition) + C(Day) + C(Condition) * C(Day)\", data_speech, groups=data_speech[\"Subject\"])\n",
    "result = model.fit()\n",
    "print(\"speech\")\n",
    "print(result.summary().as_text())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70236cfb",
   "metadata": {},
   "source": [
    "## Speech and Music Repetition: First Hearing - Second Hearing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load TRF for control conditions\n",
    "TRF_control = {}\n",
    "for condition in condition_list_control: \n",
    "        TRF_control[condition] = {}\n",
    "        print(condition)\n",
    "        for pick in picks_H: \n",
    "                TRF_control[condition][pick] = {}\n",
    "                TRF_control[condition][pick]['score'] = TRF1[condition][pick]['score']\n",
    "                TRF_control[condition][pick]['coefs'] = TRF1[condition][pick]['coefs']\n",
    "                TRF_control[condition][pick]['predicted_Y'] = TRF1[condition][pick]['predicted_Y']\n",
    "                TRF_control[condition][pick]['times'] = TRF1[condition][pick]['times'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "channel_assignment = [0, 6, 8, 12, len(picks_H)]\n",
    "\n",
    "for n, contrast in enumerate(contrasts_control):\n",
    "    print(contrast)\n",
    "    if \"music\" in contrast[0]: \n",
    "        color_prod = 'purple'\n",
    "        color_perc = 'plum'\n",
    "    elif \"speech\" in contrast[0]: \n",
    "        color_prod = '#008000'\n",
    "        color_perc = '#90EE90'\n",
    "\n",
    "    data_firsthearing = np.array([TRF_control[contrast[0]][pick]['score'] for pick in picks_H])\n",
    "    data_secondhearing = np.array([TRF_control[contrast[1]][pick]['score'] for pick in picks_H])\n",
    "\n",
    "    mean_firsthearing = np.mean(data_firsthearing, axis=1)\n",
    "    se_firsthearing = np.std(data_firsthearing, axis=1, ddof=1) / np.sqrt(len(data_firsthearing[0]))\n",
    "\n",
    "    mean_secondhearing = np.mean(data_secondhearing, axis=1)\n",
    "    se_secondhearing = np.std(data_secondhearing, axis=1, ddof=1) / np.sqrt(len(data_secondhearing[0]))\n",
    "\n",
    "    # t-test\n",
    "    t, p = stats.ttest_rel(data_firsthearing.T, data_secondhearing.T)\n",
    "    p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)    \n",
    "    print(p_corrected < 0.05)\n",
    "    significance_threshold = 0.05\n",
    "    significant_channels = np.where(p_corrected < significance_threshold)[0]\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax2 = ax.twinx()  \n",
    "\n",
    "    ## plot data points \n",
    "    jitter_width = 0.15 \n",
    "    for i in range(len(data_firsthearing)):\n",
    "        jitter_prod = np.random.uniform(-jitter_width, jitter_width, size=len(data_firsthearing[i]))\n",
    "        jitter_perc = np.random.uniform(-jitter_width, jitter_width, size=len(data_secondhearing[i]))\n",
    "\n",
    "        ax.scatter(data_firsthearing[i], np.full(len(data_firsthearing[i]), i) + jitter_prod,\n",
    "                alpha=0.7, color=color_prod, s=10)\n",
    "        ax.scatter(data_secondhearing[i], np.full(len(data_secondhearing[i]), i) + jitter_perc,\n",
    "                alpha=0.7, color=color_perc, s=10)\n",
    "        \n",
    "    ## plot means, se  \n",
    "    for c in range(len(channel_assignment)-1):\n",
    "        ax.errorbar(mean_firsthearing[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_firsthearing[channel_assignment[c]:channel_assignment[c+1]], marker='o', linestyle='-', color=color_prod, capsize=8)\n",
    "        ax.errorbar(mean_secondhearing[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_secondhearing[channel_assignment[c]:channel_assignment[c+1]], marker='s', linestyle='-', color=color_perc, capsize=8)\n",
    "    \n",
    "    ## plot significant differences\n",
    "    for s in range(len(picks_H)):\n",
    "        if p_corrected[s] < 0.05:\n",
    "            x_pos = -0.225\n",
    "            y_pos = s - 0.15\n",
    "            ax.text(x_pos, y_pos, \"*\", fontsize=20, color='black', ha='center', va='center', zorder=3)\n",
    "        \n",
    "\n",
    "    #ax.set_title(f'r$^2$ Coeffients for {contrast_names_control[n]} \\n', fontsize=16)\n",
    "    ax.set_xlabel('r$^2$ Coefficients', fontsize=14)\n",
    "    ax.set_ylabel('Channels', fontsize=14)\n",
    "    ax.set_xlim([-0.25, 0.55])\n",
    "    ax.set_yticks(np.arange(len(picks_H)))\n",
    "    ax.set_yticklabels(picks_H, fontsize=10)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "        ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1)\n",
    "    ax2.set_ylim(ax.get_ylim()) \n",
    "    channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "    ax2.set_yticks(channel_midpoints)  \n",
    "    ax2.set_yticklabels(brain_label, size=10, va='center')  \n",
    "\n",
    "    ax.legend([\"First Hearing\", \"Second Hearing\"])\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c614205",
   "metadata": {},
   "outputs": [],
   "source": [
    "channel_index = np.r_[42:50, 89:96]\n",
    "picks_H = [picks[index] for index in channel_index]\n",
    "brain_label = [\"Right Primary \\n Auditory Cortex\", \"Right Associative \\n Auditory Cortex\", \"Left Primary \\n Auditory Cortex\", \"Left Associative \\n Auditory Cortex\"]\n",
    "channel_position = [[0,5], [6,7], [8,11], [11,len(picks_H)]]\n",
    "channel_assignment = [0, 6, 8, 12, len(picks_H)]\n",
    "\n",
    "for n, contrast in enumerate(contrasts_control):\n",
    "    print(contrast)\n",
    "    if \"music\" in contrast[0]: \n",
    "        color_prod = 'purple'\n",
    "        color_perc = 'plum'\n",
    "    elif \"speech\" in contrast[0]: \n",
    "        color_prod = '#008000'\n",
    "        color_perc = '#90EE90'\n",
    "\n",
    "    data_firsthearing = np.array([TRF_control[contrast[0]][pick]['score'] for pick in picks_H])\n",
    "    data_secondhearing = np.array([TRF_control[contrast[1]][pick]['score'] for pick in picks_H])\n",
    "\n",
    "    mean_firsthearing = np.mean(data_firsthearing, axis=1)\n",
    "    se_firsthearing = np.std(data_firsthearing, axis=1, ddof=1) / np.sqrt(len(data_firsthearing[0]))\n",
    "\n",
    "    mean_secondhearing = np.mean(data_secondhearing, axis=1)\n",
    "    se_secondhearing = np.std(data_secondhearing, axis=1, ddof=1) / np.sqrt(len(data_secondhearing[0]))\n",
    "\n",
    "    # t-test\n",
    "    t, p = stats.stats.ttest_rel(data_firsthearing.T, data_secondhearing.T)\n",
    "    p_corrected = multipletests(p.flatten(), method='fdr_bh')[1].reshape(p.shape)    \n",
    "    print(p_corrected < 0.05)\n",
    "    significance_threshold = 0.05\n",
    "    significant_channels = np.where(p_corrected < significance_threshold)[0]\n",
    "\n",
    "    # plot\n",
    "    fig, ax = plt.subplots(figsize=(12, 8))\n",
    "    ax2 = ax.twinx()  \n",
    "  \n",
    "    ## plot means, se  \n",
    "    for c in range(len(channel_assignment)-1):\n",
    "        ax.errorbar(mean_firsthearing[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_firsthearing[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_prod, capsize=8)\n",
    "        ax.errorbar(mean_secondhearing[channel_assignment[c]:channel_assignment[c+1]], picks_H[channel_assignment[c]:channel_assignment[c+1]], xerr=se_secondhearing[channel_assignment[c]:channel_assignment[c+1]], marker='o', color=color_perc, capsize=8)\n",
    "    \n",
    "\n",
    "    ## plot significant differences\n",
    "    for s in range(len(picks_H)):\n",
    "        if p_corrected[s] < 0.05:\n",
    "            x_pos = - 0.025\n",
    "            y_pos = s - 0.15\n",
    "            ax.text(x_pos, y_pos, \"*\", fontsize=20, color='black', ha='center', va='center', zorder=3)\n",
    "\n",
    "    ax.set_xlabel('\\n r$^2$-coefficients', fontsize=16)\n",
    "    ax.tick_params(axis='x', labelsize=16)\n",
    "    ax.set_ylabel('Channels', fontsize=16)\n",
    "    ax.set_xlim([-0.05, 0.42])\n",
    "    ax.set_yticks(np.arange(len(picks_H)))\n",
    "    ax.set_yticklabels(picks_H, fontsize=14)\n",
    "    ax.grid(True, which='both', linestyle='--', linewidth=0.5)\n",
    "    for channel_pos_index in [[0,5], [5,7], [7,11]]: \n",
    "        ax.axhline(channel_pos_index[1] + 0.5, color=\"black\", lw=1)\n",
    "    ax2.set_ylim(ax.get_ylim()) \n",
    "    channel_midpoints = [(index[0] + index[1]) / 2 for index in channel_position]\n",
    "    ax2.set_yticks(channel_midpoints)  \n",
    "    ax2.set_yticklabels(brain_label, size=14, va='center')  \n",
    "\n",
    "    legend_handles = [\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=color_prod, markersize=15, label='First Hearing'),\n",
    "        Line2D([0], [0], marker='o', color='w', markerfacecolor=color_perc, markersize=15, label='Second Hearing')\n",
    "    ]\n",
    "\n",
    "    ax.legend(handles=legend_handles, fontsize=13) \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Mixed Effect Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e325b19",
   "metadata": {},
   "source": [
    "#### Model for music"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for condition in ['perceive_music_new', 'perceive_music_newrepetition']:\n",
    "    for pick in picks_H:\n",
    "        score = TRF_control[condition][pick]['score']\n",
    "        for sc in score:  \n",
    "            data.append({'Subject': 'BouNi', 'Condition': condition, 'Channel': pick, 'Score': sc})\n",
    "\n",
    "data_music = pd.DataFrame(data)\n",
    "\n",
    "data_music['Condition'] = pd.Categorical(data_music['Condition'], \n",
    "                                          categories=['perceive_music_new', 'perceive_music_newrepetition'],\n",
    "                                          ordered=True)         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Score ~ Condition\", data_music, groups=data_music[\"Subject\"])\n",
    "result = model.fit()\n",
    "print(\"music\")\n",
    "print(result.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "973dd582",
   "metadata": {},
   "source": [
    "#### Model for speech "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "for condition in ['perceive_speech_new', 'perceive_speech_newrepetition']:\n",
    "    for pick in picks_H:\n",
    "        score = TRF_control[condition][pick]['score']\n",
    "        for sc in score:  \n",
    "            data.append({'Subject': 'BouNi', 'Condition': condition, 'Channel': pick, 'Score': sc})\n",
    "\n",
    "data_speech = pd.DataFrame(data)\n",
    "\n",
    "data_speech['Condition'] = pd.Categorical(data_speech['Condition'], \n",
    "                                          categories=['perceive_speech_new', 'perceive_speech_newrepetition'],\n",
    "                                          ordered=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smf.mixedlm(\"Score ~ Condition\", data_speech, groups=data_speech[\"Subject\"])\n",
    "result = model.fit()\n",
    "print(\"speech\")\n",
    "print(result.summary())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
